{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dd05314",
   "metadata": {},
   "source": [
    "# Evaluating a PyCon Assistant Copilot using Azure AI Evaluation SDK\n",
    "\n",
    "This notebook demonstrates how to evaluate a custom copilot that acts as a PyCon conference assistant using the Azure AI Evaluation SDK. We'll set up evaluation datasets, define custom evaluation criteria, and analyze the assistant's responses for quality, relevance, and helpfulness in the context of Python conference information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b60cbc4",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "First, let's install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "390b1669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azure-ai-evaluation\n",
      "  Using cached azure_ai_evaluation-1.5.0-py3-none-any.whl.metadata (35 kB)\n",
      "Collecting azure-identity\n",
      "  Using cached azure_identity-1.21.0-py3-none-any.whl.metadata (81 kB)\n",
      "Collecting azure-identity\n",
      "  Using cached azure_identity-1.21.0-py3-none-any.whl.metadata (81 kB)\n",
      "Collecting openai\n",
      "Collecting openai\n",
      "  Downloading openai-1.76.1-py3-none-any.whl.metadata (25 kB)\n",
      "  Downloading openai-1.76.1-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting promptflow-devkit>=1.17.1 (from azure-ai-evaluation)\n",
      "  Using cached promptflow_devkit-1.17.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting promptflow-devkit>=1.17.1 (from azure-ai-evaluation)\n",
      "  Using cached promptflow_devkit-1.17.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting promptflow-core>=1.17.1 (from azure-ai-evaluation)\n",
      "Collecting promptflow-core>=1.17.1 (from azure-ai-evaluation)\n",
      "  Using cached promptflow_core-1.17.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "  Using cached promptflow_core-1.17.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting pyjwt>=2.8.0 (from azure-ai-evaluation)\n",
      "  Using cached PyJWT-2.10.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting pyjwt>=2.8.0 (from azure-ai-evaluation)\n",
      "  Using cached PyJWT-2.10.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting azure-core>=1.30.2 (from azure-ai-evaluation)\n",
      "  Using cached azure_core-1.33.0-py3-none-any.whl.metadata (42 kB)\n",
      "Collecting azure-core>=1.30.2 (from azure-ai-evaluation)\n",
      "  Using cached azure_core-1.33.0-py3-none-any.whl.metadata (42 kB)\n",
      "Collecting nltk>=3.9.1 (from azure-ai-evaluation)\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting nltk>=3.9.1 (from azure-ai-evaluation)\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting azure-storage-blob>=12.10.0 (from azure-ai-evaluation)\n",
      "  Using cached azure_storage_blob-12.25.1-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting azure-storage-blob>=12.10.0 (from azure-ai-evaluation)\n",
      "  Using cached azure_storage_blob-12.25.1-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting httpx>=0.25.1 (from azure-ai-evaluation)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting httpx>=0.25.1 (from azure-ai-evaluation)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting pandas<3.0.0,>=2.1.2 (from azure-ai-evaluation)\n",
      "Collecting pandas<3.0.0,>=2.1.2 (from azure-ai-evaluation)\n",
      "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "Collecting ruamel.yaml<1.0.0,>=0.17.10 (from azure-ai-evaluation)\n",
      "  Using cached ruamel.yaml-0.18.10-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting ruamel.yaml<1.0.0,>=0.17.10 (from azure-ai-evaluation)\n",
      "  Using cached ruamel.yaml-0.18.10-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting msrest>=0.6.21 (from azure-ai-evaluation)\n",
      "  Using cached msrest-0.7.1-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting msrest>=0.6.21 (from azure-ai-evaluation)\n",
      "  Using cached msrest-0.7.1-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting numpy>=1.23.2 (from pandas<3.0.0,>=2.1.2->azure-ai-evaluation)\n",
      "  Downloading numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Collecting numpy>=1.23.2 (from pandas<3.0.0,>=2.1.2->azure-ai-evaluation)\n",
      "  Downloading numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.11/site-packages (from pandas<3.0.0,>=2.1.2->azure-ai-evaluation) (2.9.0.post0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.11/site-packages (from pandas<3.0.0,>=2.1.2->azure-ai-evaluation) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas<3.0.0,>=2.1.2->azure-ai-evaluation)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting pytz>=2020.1 (from pandas<3.0.0,>=2.1.2->azure-ai-evaluation)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas<3.0.0,>=2.1.2->azure-ai-evaluation)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas<3.0.0,>=2.1.2->azure-ai-evaluation)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml<1.0.0,>=0.17.10->azure-ai-evaluation)\n",
      "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml<1.0.0,>=0.17.10->azure-ai-evaluation)\n",
      "  Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
      "  Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting cryptography>=2.5 (from azure-identity)\n",
      "  Using cached cryptography-44.0.2-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (5.7 kB)\n",
      "Collecting msal>=1.30.0 (from azure-identity)\n",
      "Collecting cryptography>=2.5 (from azure-identity)\n",
      "  Using cached cryptography-44.0.2-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (5.7 kB)\n",
      "Collecting msal>=1.30.0 (from azure-identity)\n",
      "  Downloading msal-1.32.3-py3-none-any.whl.metadata (11 kB)\n",
      "  Downloading msal-1.32.3-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting msal-extensions>=1.2.0 (from azure-identity)\n",
      "  Using cached msal_extensions-1.3.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in ./.venv/lib/python3.11/site-packages (from azure-identity) (4.13.2)\n",
      "Collecting msal-extensions>=1.2.0 (from azure-identity)\n",
      "  Using cached msal_extensions-1.3.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in ./.venv/lib/python3.11/site-packages (from azure-identity) (4.13.2)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Using cached anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from openai)\n",
      "  Using cached anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Using cached pydantic-2.11.3-py3-none-any.whl.metadata (65 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai)\n",
      "  Using cached pydantic-2.11.3-py3-none-any.whl.metadata (65 kB)\n",
      "Collecting sniffio (from openai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting sniffio (from openai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>4 (from openai)\n",
      "Collecting tqdm>4 (from openai)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting idna>=2.8 (from anyio<5,>=3.5.0->openai)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting idna>=2.8 (from anyio<5,>=3.5.0->openai)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting certifi (from httpx>=0.25.1->azure-ai-evaluation)\n",
      "Collecting certifi (from httpx>=0.25.1->azure-ai-evaluation)\n",
      "  Downloading certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)\n",
      "  Downloading certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx>=0.25.1->azure-ai-evaluation)\n",
      "Collecting httpcore==1.* (from httpx>=0.25.1->azure-ai-evaluation)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx>=0.25.1->azure-ai-evaluation)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx>=0.25.1->azure-ai-evaluation)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.1 (from pydantic<3,>=1.9.0->openai)\n",
      "Collecting pydantic-core==2.33.1 (from pydantic<3,>=1.9.0->openai)\n",
      "  Downloading pydantic_core-2.33.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "  Downloading pydantic_core-2.33.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3,>=1.9.0->openai)\n",
      "  Using cached typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting requests>=2.21.0 (from azure-core>=1.30.2->azure-ai-evaluation)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: six>=1.11.0 in ./.venv/lib/python3.11/site-packages (from azure-core>=1.30.2->azure-ai-evaluation) (1.17.0)\n",
      "Collecting requests>=2.21.0 (from azure-core>=1.30.2->azure-ai-evaluation)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: six>=1.11.0 in ./.venv/lib/python3.11/site-packages (from azure-core>=1.30.2->azure-ai-evaluation) (1.17.0)\n",
      "Collecting isodate>=0.6.1 (from azure-storage-blob>=12.10.0->azure-ai-evaluation)\n",
      "  Using cached isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting isodate>=0.6.1 (from azure-storage-blob>=12.10.0->azure-ai-evaluation)\n",
      "  Using cached isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting cffi>=1.12 (from cryptography>=2.5->azure-identity)\n",
      "  Using cached cffi-1.17.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting cffi>=1.12 (from cryptography>=2.5->azure-identity)\n",
      "  Using cached cffi-1.17.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting pycparser (from cffi>=1.12->cryptography>=2.5->azure-identity)\n",
      "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Collecting pycparser (from cffi>=1.12->cryptography>=2.5->azure-identity)\n",
      "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Collecting charset-normalizer<4,>=2 (from requests>=2.21.0->azure-core>=1.30.2->azure-ai-evaluation)\n",
      "  Using cached charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests>=2.21.0->azure-core>=1.30.2->azure-ai-evaluation)\n",
      "  Using cached charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.21.0->azure-core>=1.30.2->azure-ai-evaluation)\n",
      "  Using cached urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.21.0->azure-core>=1.30.2->azure-ai-evaluation)\n",
      "  Using cached urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting requests-oauthlib>=0.5.0 (from msrest>=0.6.21->azure-ai-evaluation)\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting requests-oauthlib>=0.5.0 (from msrest>=0.6.21->azure-ai-evaluation)\n",
      "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting click (from nltk>=3.9.1->azure-ai-evaluation)\n",
      "Collecting click (from nltk>=3.9.1->azure-ai-evaluation)\n",
      "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting joblib (from nltk>=3.9.1->azure-ai-evaluation)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting joblib (from nltk>=3.9.1->azure-ai-evaluation)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk>=3.9.1->azure-ai-evaluation)\n",
      "Collecting regex>=2021.8.3 (from nltk>=3.9.1->azure-ai-evaluation)\n",
      "  Downloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "  Downloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting docstring_parser (from promptflow-core>=1.17.1->azure-ai-evaluation)\n",
      "Collecting docstring_parser (from promptflow-core>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "  Using cached docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting fastapi<1.0.0,>=0.109.0 (from promptflow-core>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting fastapi<1.0.0,>=0.109.0 (from promptflow-core>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting filetype>=1.2.0 (from promptflow-core>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting filetype>=1.2.0 (from promptflow-core>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting flask<4.0.0,>=2.2.3 (from promptflow-core>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached flask-3.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting flask<4.0.0,>=2.2.3 (from promptflow-core>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached flask-3.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting jsonschema<5.0.0,>=4.0.0 (from promptflow-core>=1.17.1->azure-ai-evaluation)\n",
      "Collecting jsonschema<5.0.0,>=4.0.0 (from promptflow-core>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting promptflow-tracing==1.17.2 (from promptflow-core>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting promptflow-tracing==1.17.2 (from promptflow-core>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached promptflow_tracing-1.17.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.11/site-packages (from promptflow-core>=1.17.1->azure-ai-evaluation) (7.0.0)\n",
      "  Using cached promptflow_tracing-1.17.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.11/site-packages (from promptflow-core>=1.17.1->azure-ai-evaluation) (7.0.0)\n",
      "Collecting opentelemetry-sdk<2.0.0,>=1.22.0 (from promptflow-tracing==1.17.2->promptflow-core>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached opentelemetry_sdk-1.32.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting opentelemetry-sdk<2.0.0,>=1.22.0 (from promptflow-tracing==1.17.2->promptflow-core>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached opentelemetry_sdk-1.32.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting tiktoken>=0.4.0 (from promptflow-tracing==1.17.2->promptflow-core>=1.17.1->azure-ai-evaluation)\n",
      "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting tiktoken>=0.4.0 (from promptflow-tracing==1.17.2->promptflow-core>=1.17.1->azure-ai-evaluation)\n",
      "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting starlette<0.47.0,>=0.40.0 (from fastapi<1.0.0,>=0.109.0->promptflow-core>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting starlette<0.47.0,>=0.40.0 (from fastapi<1.0.0,>=0.109.0->promptflow-core>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting Werkzeug>=3.1 (from flask<4.0.0,>=2.2.3->promptflow-core>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting Werkzeug>=3.1 (from flask<4.0.0,>=2.2.3->promptflow-core>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting Jinja2>=3.1.2 (from flask<4.0.0,>=2.2.3->promptflow-core>=1.17.1->azure-ai-evaluation)\n",
      "Collecting Jinja2>=3.1.2 (from flask<4.0.0,>=2.2.3->promptflow-core>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting itsdangerous>=2.2 (from flask<4.0.0,>=2.2.3->promptflow-core>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting itsdangerous>=2.2 (from flask<4.0.0,>=2.2.3->promptflow-core>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting blinker>=1.9 (from flask<4.0.0,>=2.2.3->promptflow-core>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "  Using cached itsdangerous-2.2.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting blinker>=1.9 (from flask<4.0.0,>=2.2.3->promptflow-core>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting attrs>=22.2.0 (from jsonschema<5.0.0,>=4.0.0->promptflow-core>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting attrs>=22.2.0 (from jsonschema<5.0.0,>=4.0.0->promptflow-core>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema<5.0.0,>=4.0.0->promptflow-core>=1.17.1->azure-ai-evaluation)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema<5.0.0,>=4.0.0->promptflow-core>=1.17.1->azure-ai-evaluation)\n",
      "  Downloading jsonschema_specifications-2025.4.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Downloading jsonschema_specifications-2025.4.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema<5.0.0,>=4.0.0->promptflow-core>=1.17.1->azure-ai-evaluation)\n",
      "Collecting referencing>=0.28.4 (from jsonschema<5.0.0,>=4.0.0->promptflow-core>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "  Using cached referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema<5.0.0,>=4.0.0->promptflow-core>=1.17.1->azure-ai-evaluation)\n",
      "  Downloading rpds_py-0.24.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema<5.0.0,>=4.0.0->promptflow-core>=1.17.1->azure-ai-evaluation)\n",
      "  Downloading rpds_py-0.24.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting opentelemetry-api==1.32.1 (from opentelemetry-sdk<2.0.0,>=1.22.0->promptflow-tracing==1.17.2->promptflow-core>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached opentelemetry_api-1.32.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting opentelemetry-api==1.32.1 (from opentelemetry-sdk<2.0.0,>=1.22.0->promptflow-tracing==1.17.2->promptflow-core>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached opentelemetry_api-1.32.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.53b1 (from opentelemetry-sdk<2.0.0,>=1.22.0->promptflow-tracing==1.17.2->promptflow-core>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached opentelemetry_semantic_conventions-0.53b1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.53b1 (from opentelemetry-sdk<2.0.0,>=1.22.0->promptflow-tracing==1.17.2->promptflow-core>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached opentelemetry_semantic_conventions-0.53b1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api==1.32.1->opentelemetry-sdk<2.0.0,>=1.22.0->promptflow-tracing==1.17.2->promptflow-core>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api==1.32.1->opentelemetry-sdk<2.0.0,>=1.22.0->promptflow-tracing==1.17.2->promptflow-core>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting importlib-metadata<8.7.0,>=6.0 (from opentelemetry-api==1.32.1->opentelemetry-sdk<2.0.0,>=1.22.0->promptflow-tracing==1.17.2->promptflow-core>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached importlib_metadata-8.6.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting importlib-metadata<8.7.0,>=6.0 (from opentelemetry-api==1.32.1->opentelemetry-sdk<2.0.0,>=1.22.0->promptflow-tracing==1.17.2->promptflow-core>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached importlib_metadata-8.6.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting zipp>=3.20 (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api==1.32.1->opentelemetry-sdk<2.0.0,>=1.22.0->promptflow-tracing==1.17.2->promptflow-core>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting zipp>=3.20 (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api==1.32.1->opentelemetry-sdk<2.0.0,>=1.22.0->promptflow-tracing==1.17.2->promptflow-core>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting wrapt<2,>=1.10 (from deprecated>=1.2.6->opentelemetry-api==1.32.1->opentelemetry-sdk<2.0.0,>=1.22.0->promptflow-tracing==1.17.2->promptflow-core>=1.17.1->azure-ai-evaluation)\n",
      "  Downloading wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting wrapt<2,>=1.10 (from deprecated>=1.2.6->opentelemetry-api==1.32.1->opentelemetry-sdk<2.0.0,>=1.22.0->promptflow-tracing==1.17.2->promptflow-core>=1.17.1->azure-ai-evaluation)\n",
      "  Downloading wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting MarkupSafe>=2.0 (from Jinja2>=3.1.2->flask<4.0.0,>=2.2.3->promptflow-core>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting MarkupSafe>=2.0 (from Jinja2>=3.1.2->flask<4.0.0,>=2.2.3->promptflow-core>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting argcomplete>=3.2.3 (from promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "Collecting argcomplete>=3.2.3 (from promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached argcomplete-3.6.2-py3-none-any.whl.metadata (16 kB)\n",
      "  Using cached argcomplete-3.6.2-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21 (from promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached azure_monitor_opentelemetry_exporter-1.0.0b36-py2.py3-none-any.whl.metadata (33 kB)\n",
      "Collecting azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21 (from promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached azure_monitor_opentelemetry_exporter-1.0.0b36-py2.py3-none-any.whl.metadata (33 kB)\n",
      "Collecting colorama<0.5.0,>=0.4.6 (from promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting colorama<0.5.0,>=0.4.6 (from promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting filelock<4.0.0,>=3.4.0 (from promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "Collecting filelock<4.0.0,>=3.4.0 (from promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting flask-cors<6.0.0,>=5.0.0 (from promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached flask_cors-5.0.1-py3-none-any.whl.metadata (961 bytes)\n",
      "Collecting flask-cors<6.0.0,>=5.0.0 (from promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached flask_cors-5.0.1-py3-none-any.whl.metadata (961 bytes)\n",
      "Collecting flask-restx<2.0.0,>=1.2.0 (from promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached flask_restx-1.3.0-py2.py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting flask-restx<2.0.0,>=1.2.0 (from promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached flask_restx-1.3.0-py2.py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting gitpython<4.0.0,>=3.1.24 (from promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting gitpython<4.0.0,>=3.1.24 (from promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting keyring<25.0.0,>=24.2.0 (from promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached keyring-24.3.1-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting keyring<25.0.0,>=24.2.0 (from promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached keyring-24.3.1-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.5 (from promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.5 (from promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0 (from promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_http-1.32.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0 (from promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_http-1.32.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting pillow<11.1.0,>=10.1.0 (from promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "Collecting pillow<11.1.0,>=10.1.0 (from promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "  Downloading pillow-11.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
      "  Downloading pillow-11.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
      "Collecting pydash<8.0.0,>=6.0.0 (from promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached pydash-7.0.7-py3-none-any.whl.metadata (45 kB)\n",
      "Collecting pydash<8.0.0,>=6.0.0 (from promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached pydash-7.0.7-py3-none-any.whl.metadata (45 kB)\n",
      "Collecting python-dotenv<2.0.0,>=1.0.0 (from promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting python-dotenv<2.0.0,>=1.0.0 (from promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting sqlalchemy<3.0.0,>=1.4.48 (from promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "Collecting sqlalchemy<3.0.0,>=1.4.48 (from promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "  Downloading sqlalchemy-2.0.40-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "  Downloading sqlalchemy-2.0.40-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting strictyaml<2.0.0,>=1.5.0 (from promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached strictyaml-1.7.3-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting strictyaml<2.0.0,>=1.5.0 (from promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached strictyaml-1.7.3-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting tabulate<1.0.0,>=0.9.0 (from promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting tabulate<1.0.0,>=0.9.0 (from promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting waitress<4.0.0,>=3.0.0 (from promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached waitress-3.0.2-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting waitress<4.0.0,>=3.0.0 (from promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached waitress-3.0.2-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting fixedint==0.1.6 (from azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "Collecting fixedint==0.1.6 (from azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached fixedint-0.1.6-py3-none-any.whl.metadata (4.8 kB)\n",
      "  Using cached fixedint-0.1.6-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting psutil (from promptflow-core>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached psutil-6.1.1-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
      "Collecting psutil (from promptflow-core>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached psutil-6.1.1-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
      "Collecting aniso8601>=0.82 (from flask-restx<2.0.0,>=1.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached aniso8601-10.0.1-py2.py3-none-any.whl.metadata (23 kB)\n",
      "Collecting aniso8601>=0.82 (from flask-restx<2.0.0,>=1.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached aniso8601-10.0.1-py2.py3-none-any.whl.metadata (23 kB)\n",
      "Collecting importlib-resources (from flask-restx<2.0.0,>=1.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting importlib-resources (from flask-restx<2.0.0,>=1.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython<4.0.0,>=3.1.24->promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython<4.0.0,>=3.1.24->promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4.0.0,>=3.1.24->promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4.0.0,>=3.1.24->promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting jaraco.classes (from keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached jaraco.classes-3.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting jaraco.classes (from keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached jaraco.classes-3.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting SecretStorage>=3.2 (from keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached SecretStorage-3.3.3-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting SecretStorage>=3.2 (from keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached SecretStorage-3.3.3-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting jeepney>=0.4.2 (from keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached jeepney-0.9.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: packaging>=17.0 in ./.venv/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.5->promptflow-devkit>=1.17.1->azure-ai-evaluation) (25.0)\n",
      "Collecting jeepney>=0.4.2 (from keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached jeepney-0.9.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: packaging>=17.0 in ./.venv/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.5->promptflow-devkit>=1.17.1->azure-ai-evaluation) (25.0)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.32.1 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.32.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.32.1 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.32.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.32.1 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached opentelemetry_proto-1.32.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-proto==1.32.1 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached opentelemetry_proto-1.32.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting protobuf<6.0,>=5.0 (from opentelemetry-proto==1.32.1->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached protobuf-5.29.4-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Collecting protobuf<6.0,>=5.0 (from opentelemetry-proto==1.32.1->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached protobuf-5.29.4-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Collecting greenlet>=1 (from sqlalchemy<3.0.0,>=1.4.48->promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "  Downloading greenlet-3.2.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting greenlet>=1 (from sqlalchemy<3.0.0,>=1.4.48->promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "  Downloading greenlet-3.2.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.5.0->msrest>=0.6.21->azure-ai-evaluation)\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.5.0->msrest>=0.6.21->azure-ai-evaluation)\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting more-itertools (from jaraco.classes->keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached more_itertools-10.7.0-py3-none-any.whl.metadata (37 kB)\n",
      "Collecting more-itertools (from jaraco.classes->keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation)\n",
      "  Using cached more_itertools-10.7.0-py3-none-any.whl.metadata (37 kB)\n",
      "Using cached azure_ai_evaluation-1.5.0-py3-none-any.whl (773 kB)\n",
      "Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[?25lUsing cached azure_ai_evaluation-1.5.0-py3-none-any.whl (773 kB)\n",
      "Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/13.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[?25hUsing cached ruamel.yaml-0.18.10-py3-none-any.whl (117 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached ruamel.yaml-0.18.10-py3-none-any.whl (117 kB)\n",
      "Using cached azure_identity-1.21.0-py3-none-any.whl (189 kB)\n",
      "Downloading openai-1.76.1-py3-none-any.whl (661 kB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/661.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mUsing cached azure_identity-1.21.0-py3-none-any.whl (189 kB)\n",
      "Downloading openai-1.76.1-py3-none-any.whl (661 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.2/661.2 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.2/661.2 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading jiter-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (351 kB)\n",
      "Using cached pydantic-2.11.3-py3-none-any.whl (443 kB)\n",
      "Downloading jiter-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (351 kB)\n",
      "Using cached pydantic-2.11.3-py3-none-any.whl (443 kB)\n",
      "Downloading pydantic_core-2.33.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mDownloading pydantic_core-2.33.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached azure_core-1.33.0-py3-none-any.whl (207 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached azure_core-1.33.0-py3-none-any.whl (207 kB)\n",
      "Using cached azure_storage_blob-12.25.1-py3-none-any.whl (406 kB)\n",
      "Using cached cryptography-44.0.2-cp39-abi3-manylinux_2_34_x86_64.whl (4.2 MB)\n",
      "Using cached cffi-1.17.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (467 kB)\n",
      "Using cached azure_storage_blob-12.25.1-py3-none-any.whl (406 kB)\n",
      "Using cached cryptography-44.0.2-cp39-abi3-manylinux_2_34_x86_64.whl (4.2 MB)\n",
      "Using cached cffi-1.17.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (467 kB)\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached isodate-0.7.2-py3-none-any.whl (22 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached isodate-0.7.2-py3-none-any.whl (22 kB)\n",
      "Downloading msal-1.32.3-py3-none-any.whl (115 kB)\n",
      "Using cached PyJWT-2.10.1-py3-none-any.whl (22 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (143 kB)\n",
      "Downloading msal-1.32.3-py3-none-any.whl (115 kB)\n",
      "Using cached PyJWT-2.10.1-py3-none-any.whl (22 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (143 kB)\n",
      "Using cached urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "Downloading certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
      "Using cached urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "Downloading certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
      "Using cached msal_extensions-1.3.1-py3-none-any.whl (20 kB)\n",
      "Using cached msrest-0.7.1-py3-none-any.whl (85 kB)\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Using cached msal_extensions-1.3.1-py3-none-any.whl (20 kB)\n",
      "Using cached msrest-0.7.1-py3-none-any.whl (85 kB)\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Downloading numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/16.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mDownloading numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached promptflow_core-1.17.2-py3-none-any.whl (987 kB)\n",
      "Using cached promptflow_tracing-1.17.2-py3-none-any.whl (26 kB)\n",
      "Using cached fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
      "Using cached flask-3.1.0-py3-none-any.whl (102 kB)\n",
      "Using cached jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "Using cached opentelemetry_sdk-1.32.1-py3-none-any.whl (118 kB)\n",
      "Using cached opentelemetry_api-1.32.1-py3-none-any.whl (65 kB)\n",
      "Using cached opentelemetry_semantic_conventions-0.53b1-py3-none-any.whl (188 kB)\n",
      "Using cached importlib_metadata-8.6.1-py3-none-any.whl (26 kB)\n",
      "Using cached starlette-0.46.2-py3-none-any.whl (72 kB)\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Using cached blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Using cached Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached promptflow_core-1.17.2-py3-none-any.whl (987 kB)\n",
      "Using cached promptflow_tracing-1.17.2-py3-none-any.whl (26 kB)\n",
      "Using cached fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
      "Using cached flask-3.1.0-py3-none-any.whl (102 kB)\n",
      "Using cached jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
      "Using cached opentelemetry_sdk-1.32.1-py3-none-any.whl (118 kB)\n",
      "Using cached opentelemetry_api-1.32.1-py3-none-any.whl (65 kB)\n",
      "Using cached opentelemetry_semantic_conventions-0.53b1-py3-none-any.whl (188 kB)\n",
      "Using cached importlib_metadata-8.6.1-py3-none-any.whl (26 kB)\n",
      "Using cached starlette-0.46.2-py3-none-any.whl (72 kB)\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Using cached blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Using cached Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Downloading wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
      "Using cached filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Using cached itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Downloading wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
      "Using cached filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Using cached itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading jsonschema_specifications-2025.4.1-py3-none-any.whl (18 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading jsonschema_specifications-2025.4.1-py3-none-any.whl (18 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
      "Using cached promptflow_devkit-1.17.2-py3-none-any.whl (7.0 MB)\n",
      "Using cached promptflow_devkit-1.17.2-py3-none-any.whl (7.0 MB)\n",
      "Using cached azure_monitor_opentelemetry_exporter-1.0.0b36-py2.py3-none-any.whl (154 kB)\n",
      "Using cached fixedint-0.1.6-py3-none-any.whl (12 kB)\n",
      "Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Using cached flask_cors-5.0.1-py3-none-any.whl (11 kB)\n",
      "Using cached azure_monitor_opentelemetry_exporter-1.0.0b36-py2.py3-none-any.whl (154 kB)\n",
      "Using cached fixedint-0.1.6-py3-none-any.whl (12 kB)\n",
      "Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Using cached flask_cors-5.0.1-py3-none-any.whl (11 kB)\n",
      "Using cached flask_restx-1.3.0-py2.py3-none-any.whl (2.8 MB)\n",
      "Using cached GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
      "Using cached gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Using cached keyring-24.3.1-py3-none-any.whl (38 kB)\n",
      "Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_http-1.32.1-py3-none-any.whl (17 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_common-1.32.1-py3-none-any.whl (18 kB)\n",
      "Using cached opentelemetry_proto-1.32.1-py3-none-any.whl (55 kB)\n",
      "Using cached googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Using cached flask_restx-1.3.0-py2.py3-none-any.whl (2.8 MB)\n",
      "Using cached GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
      "Using cached gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Using cached keyring-24.3.1-py3-none-any.whl (38 kB)\n",
      "Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_http-1.32.1-py3-none-any.whl (17 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_common-1.32.1-py3-none-any.whl (18 kB)\n",
      "Using cached opentelemetry_proto-1.32.1-py3-none-any.whl (55 kB)\n",
      "Using cached googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Downloading pillow-11.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.4 MB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/4.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mDownloading pillow-11.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached protobuf-5.29.4-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "Using cached psutil-6.1.1-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)\n",
      "Using cached pydash-7.0.7-py3-none-any.whl (110 kB)\n",
      "Using cached python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached protobuf-5.29.4-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "Using cached psutil-6.1.1-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)\n",
      "Using cached pydash-7.0.7-py3-none-any.whl (110 kB)\n",
      "Using cached python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Using cached smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Downloading sqlalchemy-2.0.40-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mUsing cached smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Downloading sqlalchemy-2.0.40-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached strictyaml-1.7.3-py3-none-any.whl (123 kB)\n",
      "Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Using cached waitress-3.0.2-py3-none-any.whl (56 kB)\n",
      "Using cached aniso8601-10.0.1-py2.py3-none-any.whl (52 kB)\n",
      "Using cached argcomplete-3.6.2-py3-none-any.whl (43 kB)\n",
      "Using cached strictyaml-1.7.3-py3-none-any.whl (123 kB)\n",
      "Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Using cached waitress-3.0.2-py3-none-any.whl (56 kB)\n",
      "Using cached aniso8601-10.0.1-py2.py3-none-any.whl (52 kB)\n",
      "Using cached argcomplete-3.6.2-py3-none-any.whl (43 kB)\n",
      "Downloading greenlet-3.2.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (583 kB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/583.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mDownloading greenlet-3.2.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (583 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m583.9/583.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached jeepney-0.9.0-py3-none-any.whl (49 kB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m583.9/583.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached jeepney-0.9.0-py3-none-any.whl (49 kB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Downloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/792.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mDownloading regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (792 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m792.7/792.7 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m792.7/792.7 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Downloading rpds_py-0.24.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (389 kB)\n",
      "Downloading rpds_py-0.24.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (389 kB)\n",
      "Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (739 kB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/739.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mDownloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (739 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.1/739.1 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached SecretStorage-3.3.3-py3-none-any.whl (15 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.1/739.1 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached SecretStorage-3.3.3-py3-none-any.whl (15 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0mDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Using cached zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Using cached zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
      "Using cached docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Using cached importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Using cached jaraco.classes-3.4.0-py3-none-any.whl (6.8 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached more_itertools-10.7.0-py3-none-any.whl (65 kB)\n",
      "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Using cached docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Using cached importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Using cached jaraco.classes-3.4.0-py3-none-any.whl (6.8 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached more_itertools-10.7.0-py3-none-any.whl (65 kB)\n",
      "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Installing collected packages: pytz, fixedint, filetype, aniso8601, zipp, wrapt, waitress, urllib3, tzdata, typing-inspection, tqdm, tabulate, sniffio, smmap, ruamel.yaml.clib, rpds-py, regex, python-dotenv, pyjwt, pydash, pydantic-core, pycparser, psutil, protobuf, pillow, oauthlib, numpy, more-itertools, marshmallow, MarkupSafe, joblib, jiter, jeepney, itsdangerous, isodate, importlib-resources, idna, h11, greenlet, filelock, docstring_parser, distro, colorama, click, charset-normalizer, certifi, blinker, attrs, argcomplete, annotated-types, Werkzeug, strictyaml, sqlalchemy, ruamel.yaml, requests, referencing, pydantic, pandas, opentelemetry-proto, nltk, Jinja2, jaraco.classes, importlib-metadata, httpcore, googleapis-common-protos, gitdb, deprecated, cffi, anyio, tiktoken, starlette, requests-oauthlib, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, jsonschema-specifications, httpx, gitpython, flask, cryptography, azure-core, SecretStorage, opentelemetry-semantic-conventions, openai, msrest, jsonschema, flask-cors, fastapi, azure-storage-blob, opentelemetry-sdk, msal, keyring, flask-restx, promptflow-tracing, opentelemetry-exporter-otlp-proto-http, msal-extensions, promptflow-core, azure-identity, azure-monitor-opentelemetry-exporter, promptflow-devkit, azure-ai-evaluation\n",
      "\u001b[?25lInstalling collected packages: pytz, fixedint, filetype, aniso8601, zipp, wrapt, waitress, urllib3, tzdata, typing-inspection, tqdm, tabulate, sniffio, smmap, ruamel.yaml.clib, rpds-py, regex, python-dotenv, pyjwt, pydash, pydantic-core, pycparser, psutil, protobuf, pillow, oauthlib, numpy, more-itertools, marshmallow, MarkupSafe, joblib, jiter, jeepney, itsdangerous, isodate, importlib-resources, idna, h11, greenlet, filelock, docstring_parser, distro, colorama, click, charset-normalizer, certifi, blinker, attrs, argcomplete, annotated-types, Werkzeug, strictyaml, sqlalchemy, ruamel.yaml, requests, referencing, pydantic, pandas, opentelemetry-proto, nltk, Jinja2, jaraco.classes, importlib-metadata, httpcore, googleapis-common-protos, gitdb, deprecated, cffi, anyio, tiktoken, starlette, requests-oauthlib, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, jsonschema-specifications, httpx, gitpython, flask, cryptography, azure-core, SecretStorage, opentelemetry-semantic-conventions, openai, msrest, jsonschema, flask-cors, fastapi, azure-storage-blob, opentelemetry-sdk, msal, keyring, flask-restx, promptflow-tracing, opentelemetry-exporter-otlp-proto-http, msal-extensions, promptflow-core, azure-identity, azure-monitor-opentelemetry-exporter, promptflow-devkit, azure-ai-evaluation\n",
      "\u001b[2K  Attempting uninstall: psutil\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 20/100\u001b[0m [pydantic-core]\n",
      "\u001b[2K    Found existing installation: psutil 7.0.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 20/100\u001b[0m [pydantic-core]\n",
      "\u001b[2K    Uninstalling psutil-7.0.0:\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 22/100\u001b[0m [psutil]re]\n",
      "\u001b[2K      Successfully uninstalled psutil-7.0.0━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 22/100\u001b[0m [psutil]\n",
      "\u001b[2K  Attempting uninstall: psutilm━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 22/100\u001b[0m [psutil]\n",
      "\u001b[2K    Found existing installation: psutil 7.0.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 20/100\u001b[0m [pydantic-core]\n",
      "\u001b[2K    Uninstalling psutil-7.0.0:\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 22/100\u001b[0m [psutil]re]\n",
      "\u001b[2K      Successfully uninstalled psutil-7.0.0━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 22/100\u001b[0m [psutil]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100/100\u001b[0m [azure-ai-evaluation]aluation]porter]oto-http]\n",
      "\u001b[1A\u001b[2KSuccessfully installed Jinja2-3.1.6 MarkupSafe-3.0.2 SecretStorage-3.3.3 Werkzeug-3.1.3 aniso8601-10.0.1 annotated-types-0.7.0 anyio-4.9.0 argcomplete-3.6.2 attrs-25.3.0 azure-ai-evaluation-1.5.0 azure-core-1.33.0 azure-identity-1.21.0 azure-monitor-opentelemetry-exporter-1.0.0b36 azure-storage-blob-12.25.1 blinker-1.9.0 certifi-2025.4.26 cffi-1.17.1 charset-normalizer-3.4.1 click-8.1.8 colorama-0.4.6 cryptography-44.0.2 deprecated-1.2.18 distro-1.9.0 docstring_parser-0.16 fastapi-0.115.12 filelock-3.18.0 filetype-1.2.0 fixedint-0.1.6 flask-3.1.0 flask-cors-5.0.1 flask-restx-1.3.0 gitdb-4.0.12 gitpython-3.1.44 googleapis-common-protos-1.70.0 greenlet-3.2.1 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.10 importlib-metadata-8.6.1 importlib-resources-6.5.2 isodate-0.7.2 itsdangerous-2.2.0 jaraco.classes-3.4.0 jeepney-0.9.0 jiter-0.9.0 joblib-1.4.2 jsonschema-4.23.0 jsonschema-specifications-2025.4.1 keyring-24.3.1 marshmallow-3.26.1 more-itertools-10.7.0 msal-1.32.3 msal-extensions-1.3.1 msrest-0.7.1 nltk-3.9.1 numpy-2.2.5 oauthlib-3.2.2 openai-1.76.1 opentelemetry-api-1.32.1 opentelemetry-exporter-otlp-proto-common-1.32.1 opentelemetry-exporter-otlp-proto-http-1.32.1 opentelemetry-proto-1.32.1 opentelemetry-sdk-1.32.1 opentelemetry-semantic-conventions-0.53b1 pandas-2.2.3 pillow-11.0.0 promptflow-core-1.17.2 promptflow-devkit-1.17.2 promptflow-tracing-1.17.2 protobuf-5.29.4 psutil-6.1.1 pycparser-2.22 pydantic-2.11.3 pydantic-core-2.33.1 pydash-7.0.7 pyjwt-2.10.1 python-dotenv-1.1.0 pytz-2025.2 referencing-0.36.2 regex-2024.11.6 requests-2.32.3 requests-oauthlib-2.0.0 rpds-py-0.24.0 ruamel.yaml-0.18.10 ruamel.yaml.clib-0.2.12 smmap-5.0.2 sniffio-1.3.1 sqlalchemy-2.0.40 starlette-0.46.2 strictyaml-1.7.3 tabulate-0.9.0 tiktoken-0.9.0 tqdm-4.67.1 typing-inspection-0.4.0 tzdata-2025.2 urllib3-2.4.0 waitress-3.0.2 wrapt-1.17.2 zipp-3.21.0\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100/100\u001b[0m [azure-ai-evaluation]\n",
      "\u001b[1A\u001b[2KSuccessfully installed Jinja2-3.1.6 MarkupSafe-3.0.2 SecretStorage-3.3.3 Werkzeug-3.1.3 aniso8601-10.0.1 annotated-types-0.7.0 anyio-4.9.0 argcomplete-3.6.2 attrs-25.3.0 azure-ai-evaluation-1.5.0 azure-core-1.33.0 azure-identity-1.21.0 azure-monitor-opentelemetry-exporter-1.0.0b36 azure-storage-blob-12.25.1 blinker-1.9.0 certifi-2025.4.26 cffi-1.17.1 charset-normalizer-3.4.1 click-8.1.8 colorama-0.4.6 cryptography-44.0.2 deprecated-1.2.18 distro-1.9.0 docstring_parser-0.16 fastapi-0.115.12 filelock-3.18.0 filetype-1.2.0 fixedint-0.1.6 flask-3.1.0 flask-cors-5.0.1 flask-restx-1.3.0 gitdb-4.0.12 gitpython-3.1.44 googleapis-common-protos-1.70.0 greenlet-3.2.1 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.10 importlib-metadata-8.6.1 importlib-resources-6.5.2 isodate-0.7.2 itsdangerous-2.2.0 jaraco.classes-3.4.0 jeepney-0.9.0 jiter-0.9.0 joblib-1.4.2 jsonschema-4.23.0 jsonschema-specifications-2025.4.1 keyring-24.3.1 marshmallow-3.26.1 more-itertools-10.7.0 msal-1.32.3 msal-extensions-1.3.1 msrest-0.7.1 nltk-3.9.1 numpy-2.2.5 oauthlib-3.2.2 openai-1.76.1 opentelemetry-api-1.32.1 opentelemetry-exporter-otlp-proto-common-1.32.1 opentelemetry-exporter-otlp-proto-http-1.32.1 opentelemetry-proto-1.32.1 opentelemetry-sdk-1.32.1 opentelemetry-semantic-conventions-0.53b1 pandas-2.2.3 pillow-11.0.0 promptflow-core-1.17.2 promptflow-devkit-1.17.2 promptflow-tracing-1.17.2 protobuf-5.29.4 psutil-6.1.1 pycparser-2.22 pydantic-2.11.3 pydantic-core-2.33.1 pydash-7.0.7 pyjwt-2.10.1 python-dotenv-1.1.0 pytz-2025.2 referencing-0.36.2 regex-2024.11.6 requests-2.32.3 requests-oauthlib-2.0.0 rpds-py-0.24.0 ruamel.yaml-0.18.10 ruamel.yaml.clib-0.2.12 smmap-5.0.2 sniffio-1.3.1 sqlalchemy-2.0.40 starlette-0.46.2 strictyaml-1.7.3 tabulate-0.9.0 tiktoken-0.9.0 tqdm-4.67.1 typing-inspection-0.4.0 tzdata-2025.2 urllib3-2.4.0 waitress-3.0.2 wrapt-1.17.2 zipp-3.21.0\n"
     ]
    }
   ],
   "source": [
    "# Install the Azure AI Evaluation SDK and other required packages\n",
    "!pip install azure-ai-evaluation azure-identity openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceece0eb",
   "metadata": {},
   "source": [
    "## Setup and Configuration\n",
    "\n",
    "Let's set up our environment variables and authentication for Azure services:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8794e798",
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "Missing credentials. Please pass one of `api_key`, `azure_ad_token`, `azure_ad_token_provider`, or the `AZURE_OPENAI_API_KEY` or `AZURE_OPENAI_AD_TOKEN` environment variables.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOpenAIError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     18\u001b[39m model_config = {\n\u001b[32m     19\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mazure_endpoint\u001b[39m\u001b[33m\"\u001b[39m: os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mAZURE_OPENAI_ENDPOINT\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     20\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mapi_key\u001b[39m\u001b[33m\"\u001b[39m: os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mAZURE_OPENAI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     21\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mapi_version\u001b[39m\u001b[33m\"\u001b[39m: os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mAZURE_OPENAI_API_VERSION\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m2023-12-01-preview\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     22\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdeployment_name\u001b[39m\u001b[33m\"\u001b[39m: os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mAZURE_OPENAI_DEPLOYMENT_NAME\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     23\u001b[39m }\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# Initialize Azure OpenAI client for our assistant simulation\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m client = \u001b[43mAzureOpenAI\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mazure_endpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mazure_endpoint\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mapi_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_version\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mapi_version\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/pycon/.venv/lib/python3.11/site-packages/openai/lib/azure.py:194\u001b[39m, in \u001b[36mAzureOpenAI.__init__\u001b[39m\u001b[34m(self, api_version, azure_endpoint, azure_deployment, api_key, azure_ad_token, azure_ad_token_provider, organization, project, websocket_base_url, base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[39m\n\u001b[32m    191\u001b[39m     azure_ad_token = os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mAZURE_OPENAI_AD_TOKEN\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m azure_ad_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m azure_ad_token_provider \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[32m    195\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mMissing credentials. Please pass one of `api_key`, `azure_ad_token`, `azure_ad_token_provider`, or the `AZURE_OPENAI_API_KEY` or `AZURE_OPENAI_AD_TOKEN` environment variables.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    196\u001b[39m     )\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m api_version \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    199\u001b[39m     api_version = os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_VERSION\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mOpenAIError\u001b[39m: Missing credentials. Please pass one of `api_key`, `azure_ad_token`, `azure_ad_token_provider`, or the `AZURE_OPENAI_API_KEY` or `AZURE_OPENAI_AD_TOKEN` environment variables."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "# Set up authentication\n",
    "credential = DefaultAzureCredential()\n",
    "\n",
    "# Initialize Azure AI project and Azure OpenAI connection\n",
    "# Replace these with your actual values or set as environment variables\n",
    "azure_ai_project = {\n",
    "    \"subscription_id\": os.environ.get(\"AZURE_SUBSCRIPTION_ID\"),\n",
    "    \"resource_group_name\": os.environ.get(\"AZURE_RESOURCE_GROUP\"),\n",
    "    \"project_name\": os.environ.get(\"AZURE_PROJECT_NAME\"),\n",
    "}\n",
    "\n",
    "# Model configuration for evaluators that use LLMs\n",
    "model_config = {\n",
    "    \"azure_endpoint\": os.environ.get(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    \"api_key\": os.environ.get(\"AZURE_OPENAI_API_KEY\"),\n",
    "    \"api_version\": os.environ.get(\"AZURE_OPENAI_API_VERSION\", \"2023-12-01-preview\"),\n",
    "    \"deployment_name\": os.environ.get(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "}\n",
    "\n",
    "# Initialize Azure OpenAI client for our assistant simulation\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=model_config[\"azure_endpoint\"],\n",
    "    api_key=model_config[\"api_key\"],\n",
    "    api_version=model_config[\"api_version\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e2a342",
   "metadata": {},
   "source": [
    "## Define PyCon Assistant System Prompt\n",
    "\n",
    "Here we'll define the system prompt that turns a general LLM into a PyCon conference assistant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3353e5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "PYCON_ASSISTANT_SYSTEM_PROMPT = \"\"\"\n",
    "You are a helpful PyCon conference assistant. Your primary role is to assist conference attendees \n",
    "with information about the conference schedule, talks, workshops, speakers, and logistics. \n",
    "\n",
    "You have the following knowledge about PyCon 2025:\n",
    "- The conference is happening May 15-23, 2025 in Pittsburgh, PA\n",
    "- Main conference days are May 17-19, with tutorials on May 15-16 and sprints on May 20-23\n",
    "- Registration opens December 15, 2024 with early bird pricing until February 1, 2025\n",
    "- The venue is the David L. Lawrence Convention Center in downtown Pittsburgh\n",
    "- Keynote speakers include Guido van Rossum, Dr. Russell Keith-Magee, and Dr. Łukasz Langa\n",
    "- There are 95 scheduled talks across 5 parallel tracks, 30 tutorials, and 15 sponsored workshops\n",
    "- Conference themes include: AI/ML, Web Development, Data Science, Python Core, and Python in Education\n",
    "\n",
    "Important policies include:\n",
    "- All attendees must follow the conference Code of Conduct\n",
    "- Refunds available up to 30 days before the conference with a 10% processing fee\n",
    "- Limited financial aid is available through an application process that closes February 28, 2025\n",
    "\n",
    "Answer questions helpfully, accurately, and concisely. If you don't know an answer, acknowledge that \n",
    "and suggest where the attendee might find the information (e.g., the registration desk, conference website, etc.).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54716c32",
   "metadata": {},
   "source": [
    "## Create a PyCon Assistant Simulation\n",
    "\n",
    "We'll create a function that simulates our PyCon assistant by using the Azure OpenAI service with our system prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67d6f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pycon_assistant(query):\n",
    "    \"\"\"Simulate a PyCon assistant by using Azure OpenAI with a specific system prompt\"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model_config[\"deployment_name\"],\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": PYCON_ASSISTANT_SYSTEM_PROMPT},\n",
    "                {\"role\": \"user\", \"content\": query}\n",
    "            ],\n",
    "            temperature=0.3,  # Lower temperature for more consistent answers\n",
    "            max_tokens=500\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error in pycon_assistant: {e}\")\n",
    "        return f\"Sorry, I encountered an error: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6499bf2f",
   "metadata": {},
   "source": [
    "## Create PyCon-Specific Test Dataset\n",
    "\n",
    "Now, let's create a dataset of PyCon-specific questions that we'll use to evaluate our assistant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a47162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test dataset with questions, relevant context, and expected answer patterns\n",
    "pycon_test_data = [\n",
    "    {\n",
    "        \"query\": \"When is PyCon 2025 happening?\",\n",
    "        \"context\": \"The conference is happening May 15-23, 2025 in Pittsburgh, PA.\",\n",
    "        \"expected_pattern\": \"May 15-23, 2025\",\n",
    "        \"category\": \"logistics\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Who are the keynote speakers?\",\n",
    "        \"context\": \"Keynote speakers include Guido van Rossum, Dr. Russell Keith-Magee, and Dr. Łukasz Langa.\",\n",
    "        \"expected_pattern\": \"Guido van Rossum|Russell Keith-Magee|Łukasz Langa\",\n",
    "        \"category\": \"speakers\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"How much does registration cost?\",\n",
    "        \"context\": \"Registration opens December 15, 2024 with early bird pricing until February 1, 2025.\",\n",
    "        \"expected_pattern\": \"\",  # No specific pricing was provided in system prompt\n",
    "        \"category\": \"registration\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Do you have a code of conduct?\",\n",
    "        \"context\": \"All attendees must follow the conference Code of Conduct.\",\n",
    "        \"expected_pattern\": \"Code of Conduct\",\n",
    "        \"category\": \"policy\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Can I get a refund if I can't attend?\",\n",
    "        \"context\": \"Refunds available up to 30 days before the conference with a 10% processing fee.\",\n",
    "        \"expected_pattern\": \"30 days|10%\",\n",
    "        \"category\": \"policy\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"How many tracks will the conference have?\",\n",
    "        \"context\": \"There are 95 scheduled talks across 5 parallel tracks, 30 tutorials, and 15 sponsored workshops.\",\n",
    "        \"expected_pattern\": \"5 parallel tracks|5 tracks\",\n",
    "        \"category\": \"schedule\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What topics will be covered at PyCon 2025?\",\n",
    "        \"context\": \"Conference themes include: AI/ML, Web Development, Data Science, Python Core, and Python in Education.\",\n",
    "        \"expected_pattern\": \"AI/ML|Web Development|Data Science|Python Core|Python in Education\",\n",
    "        \"category\": \"content\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Is there financial aid available?\",\n",
    "        \"context\": \"Limited financial aid is available through an application process that closes February 28, 2025.\",\n",
    "        \"expected_pattern\": \"financial aid|application|February 28\",\n",
    "        \"category\": \"logistics\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Where exactly is the conference venue located?\",\n",
    "        \"context\": \"The venue is the David L. Lawrence Convention Center in downtown Pittsburgh.\",\n",
    "        \"expected_pattern\": \"David L. Lawrence Convention Center|downtown Pittsburgh\",\n",
    "        \"category\": \"logistics\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"When do the tutorial sessions happen?\",\n",
    "        \"context\": \"Main conference days are May 17-19, with tutorials on May 15-16 and sprints on May 20-23.\",\n",
    "        \"expected_pattern\": \"May 15-16\",\n",
    "        \"category\": \"schedule\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Generate responses from our PyCon assistant\n",
    "for item in pycon_test_data:\n",
    "    item[\"response\"] = pycon_assistant(item[\"query\"])\n",
    "\n",
    "# Save the sample data to a JSONL file\n",
    "with open(\"pycon_test_data.jsonl\", \"w\") as f:\n",
    "    for item in pycon_test_data:\n",
    "        f.write(json.dumps(item) + \"\\n\")\n",
    "\n",
    "# Display a few examples of the assistant's responses\n",
    "for i in range(3):  # Show first 3 examples\n",
    "    print(f\"Query: {pycon_test_data[i]['query']}\")\n",
    "    print(f\"Response: {pycon_test_data[i]['response']}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ecb279",
   "metadata": {},
   "source": [
    "## Create Custom Evaluators for PyCon Assistant\n",
    "\n",
    "Now, let's create some custom evaluators specifically designed to evaluate a conference assistant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53119f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from azure.ai.evaluation import (\n",
    "    GroundednessEvaluator,\n",
    "    RelevanceEvaluator,\n",
    "    CoherenceEvaluator,\n",
    "    FluencyEvaluator\n",
    ")\n",
    "\n",
    "# Initialize built-in evaluators\n",
    "groundedness_eval = GroundednessEvaluator(model_config)\n",
    "relevance_eval = RelevanceEvaluator(model_config)\n",
    "coherence_eval = CoherenceEvaluator(model_config)\n",
    "fluency_eval = FluencyEvaluator(model_config)\n",
    "\n",
    "# Create a simple custom evaluator to check if the response contains expected information\n",
    "class ExpectedPatternEvaluator:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, *, response: str, expected_pattern: str, **kwargs):\n",
    "        # If no pattern is provided, this test is not applicable\n",
    "        if not expected_pattern:\n",
    "            return {\n",
    "                \"value\": None,\n",
    "                \"reason\": \"No expected pattern provided for this query.\"\n",
    "            }\n",
    "        \n",
    "        # Check if the response contains any of the expected patterns (separated by |)\n",
    "        patterns = expected_pattern.split('|')\n",
    "        matches = [bool(re.search(pattern, response, re.IGNORECASE)) for pattern in patterns]\n",
    "        match_ratio = sum(matches) / len(patterns) if patterns else 0\n",
    "        \n",
    "        return {\n",
    "            \"value\": 1.0 if any(matches) else 0.0,  # Binary score: 1 if any pattern matches, 0 otherwise\n",
    "            \"match_ratio\": match_ratio,  # Proportion of patterns that matched\n",
    "            \"matched_patterns\": [patterns[i] for i, m in enumerate(matches) if m],\n",
    "            \"reason\": f\"Found {sum(matches)} of {len(patterns)} expected patterns in the response.\"\n",
    "        }\n",
    "\n",
    "# Create a custom evaluator for conference-specific tone and helpfulness\n",
    "class ConferenceAssistantEvaluator:\n",
    "    def __init__(self, model_config):\n",
    "        self.model_config = model_config\n",
    "        \n",
    "    def __call__(self, *, query: str, response: str, category: str, **kwargs):\n",
    "        # Use Azure OpenAI to evaluate the assistant's response\n",
    "        try:\n",
    "            eval_client = AzureOpenAI(\n",
    "                azure_endpoint=self.model_config[\"azure_endpoint\"],\n",
    "                api_key=self.model_config[\"api_key\"],\n",
    "                api_version=self.model_config[\"api_version\"]\n",
    "            )\n",
    "            \n",
    "            # Create an evaluation prompt\n",
    "            eval_prompt = f\"\"\"\n",
    "            Please evaluate the following response from a PyCon conference assistant based on the criteria below:\n",
    "            \n",
    "            Question: {query}\n",
    "            Response: {response}\n",
    "            Question Category: {category}\n",
    "            \n",
    "            Evaluate on a scale of 1-5 (where 5 is best) for each:\n",
    "            1. Helpfulness: Does it directly address the attendee's need?\n",
    "            2. Friendliness: Is the tone welcoming and appropriate for a conference assistant?\n",
    "            3. Conciseness: Is the answer appropriately brief while being complete?\n",
    "            4. Accuracy: Based on common knowledge about tech conferences (not specific PyCon details).\n",
    "            \n",
    "            Provide your scores and a brief 1-2 sentence rationale for each.\n",
    "            \n",
    "            Format your response as a JSON object with the following structure:\n",
    "            {{\n",
    "                \"helpfulness\": {{\"score\": [1-5], \"rationale\": \"your rationale\"}},\n",
    "                \"friendliness\": {{\"score\": [1-5], \"rationale\": \"your rationale\"}},\n",
    "                \"conciseness\": {{\"score\": [1-5], \"rationale\": \"your rationale\"}},\n",
    "                \"accuracy\": {{\"score\": [1-5], \"rationale\": \"your rationale\"}},\n",
    "                \"overall\": {{\"score\": [1-5], \"rationale\": \"your rationale\"}}  \n",
    "            }}\n",
    "            \"\"\"\n",
    "            \n",
    "            response = eval_client.chat.completions.create(\n",
    "                model=self.model_config[\"deployment_name\"],\n",
    "                messages=[{\"role\": \"user\", \"content\": eval_prompt}],\n",
    "                response_format={\"type\": \"json_object\"},\n",
    "                temperature=0.1\n",
    "            )\n",
    "            \n",
    "            # Parse and return the evaluation\n",
    "            result = json.loads(response.choices[0].message.content)\n",
    "            \n",
    "            # Calculate average score across all dimensions\n",
    "            scores = [result[key][\"score\"] for key in [\"helpfulness\", \"friendliness\", \"conciseness\", \"accuracy\"]]\n",
    "            result[\"average_score\"] = sum(scores) / len(scores)\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in ConferenceAssistantEvaluator: {e}\")\n",
    "            return {\n",
    "                \"error\": str(e),\n",
    "                \"helpfulness\": {\"score\": 0, \"rationale\": \"Evaluation failed\"},\n",
    "                \"friendliness\": {\"score\": 0, \"rationale\": \"Evaluation failed\"},\n",
    "                \"conciseness\": {\"score\": 0, \"rationale\": \"Evaluation failed\"},\n",
    "                \"accuracy\": {\"score\": 0, \"rationale\": \"Evaluation failed\"},\n",
    "                \"overall\": {\"score\": 0, \"rationale\": \"Evaluation failed\"},\n",
    "                \"average_score\": 0\n",
    "            }\n",
    "\n",
    "# Initialize our custom evaluators\n",
    "expected_pattern_eval = ExpectedPatternEvaluator()\n",
    "conference_assistant_eval = ConferenceAssistantEvaluator(model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb45562",
   "metadata": {},
   "source": [
    "## Run Evaluation on the Test Dataset\n",
    "\n",
    "Now let's evaluate our PyCon assistant using both built-in and custom evaluators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340429db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.evaluation import evaluate\n",
    "\n",
    "# Run the evaluation on our test dataset\n",
    "result = evaluate(\n",
    "    data=\"pycon_test_data.jsonl\",  # path to the data file\n",
    "    evaluators={\n",
    "        \"groundedness\": groundedness_eval,\n",
    "        \"relevance\": relevance_eval,\n",
    "        \"coherence\": coherence_eval,\n",
    "        \"fluency\": fluency_eval,\n",
    "        \"expected_pattern\": expected_pattern_eval,\n",
    "        \"conference_assistant\": conference_assistant_eval\n",
    "    },\n",
    "    # Column mapping to tell the evaluator which columns to use\n",
    "    evaluator_config={\n",
    "        \"groundedness\": {\n",
    "            \"column_mapping\": {\n",
    "                \"query\": \"${data.query}\",\n",
    "                \"context\": \"${data.context}\",\n",
    "                \"response\": \"${data.response}\"\n",
    "            }\n",
    "        },\n",
    "        \"relevance\": {\n",
    "            \"column_mapping\": {\n",
    "                \"query\": \"${data.query}\",\n",
    "                \"response\": \"${data.response}\"\n",
    "            }\n",
    "        },\n",
    "        \"coherence\": {\n",
    "            \"column_mapping\": {\n",
    "                \"response\": \"${data.response}\"\n",
    "            }\n",
    "        },\n",
    "        \"fluency\": {\n",
    "            \"column_mapping\": {\n",
    "                \"response\": \"${data.response}\"\n",
    "            }\n",
    "        },\n",
    "        \"expected_pattern\": {\n",
    "            \"column_mapping\": {\n",
    "                \"response\": \"${data.response}\",\n",
    "                \"expected_pattern\": \"${data.expected_pattern}\"\n",
    "            }\n",
    "        },\n",
    "        \"conference_assistant\": {\n",
    "            \"column_mapping\": {\n",
    "                \"query\": \"${data.query}\",\n",
    "                \"response\": \"${data.response}\",\n",
    "                \"category\": \"${data.category}\"\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    # Output path to save results\n",
    "    output_path=\"./pycon_assistant_evaluation_results.json\"\n",
    ")\n",
    "\n",
    "# Print evaluation results\n",
    "print(\"Aggregate Metrics:\")\n",
    "print(json.dumps(result[\"metrics\"], indent=2))\n",
    "print(\"\\nRow-level Results (first row):\")\n",
    "print(json.dumps(result[\"rows\"][0], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5200f4",
   "metadata": {},
   "source": [
    "## Analyze the Evaluation Results\n",
    "\n",
    "Let's analyze the evaluation results to identify strengths and areas for improvement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fa9320",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the evaluation results\n",
    "with open(\"pycon_assistant_evaluation_results.json\", \"r\") as f:\n",
    "    eval_results = json.load(f)\n",
    "\n",
    "# Create a DataFrame from the row-level results\n",
    "rows_data = []\n",
    "for row in eval_results[\"rows\"]:\n",
    "    row_data = {\n",
    "        \"query\": row[\"data\"][\"query\"],\n",
    "        \"category\": row[\"data\"][\"category\"],\n",
    "        \"groundedness\": row[\"outputs\"][\"groundedness\"][\"value\"] if \"groundedness\" in row[\"outputs\"] else None,\n",
    "        \"relevance\": row[\"outputs\"][\"relevance\"][\"value\"] if \"relevance\" in row[\"outputs\"] else None,\n",
    "        \"coherence\": row[\"outputs\"][\"coherence\"][\"value\"] if \"coherence\" in row[\"outputs\"] else None,\n",
    "        \"fluency\": row[\"outputs\"][\"fluency\"][\"value\"] if \"fluency\" in row[\"outputs\"] else None,\n",
    "        \"expected_pattern\": row[\"outputs\"][\"expected_pattern\"][\"value\"] if \"expected_pattern\" in row[\"outputs\"] else None,\n",
    "    }\n",
    "    \n",
    "    # Add conference assistant specific scores if available\n",
    "    if \"conference_assistant\" in row[\"outputs\"]:\n",
    "        conf_scores = row[\"outputs\"][\"conference_assistant\"]\n",
    "        if \"helpfulness\" in conf_scores:\n",
    "            row_data[\"helpfulness\"] = conf_scores[\"helpfulness\"][\"score\"]\n",
    "        if \"friendliness\" in conf_scores:\n",
    "            row_data[\"friendliness\"] = conf_scores[\"friendliness\"][\"score\"]\n",
    "        if \"conciseness\" in conf_scores:\n",
    "            row_data[\"conciseness\"] = conf_scores[\"conciseness\"][\"score\"]\n",
    "        if \"accuracy\" in conf_scores:\n",
    "            row_data[\"accuracy\"] = conf_scores[\"accuracy\"][\"score\"]\n",
    "        if \"overall\" in conf_scores:\n",
    "            row_data[\"overall\"] = conf_scores[\"overall\"][\"score\"]\n",
    "        if \"average_score\" in conf_scores:\n",
    "            row_data[\"average_score\"] = conf_scores[\"average_score\"]\n",
    "    \n",
    "    rows_data.append(row_data)\n",
    "\n",
    "df = pd.DataFrame(rows_data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"Evaluation Results by Query:\")\n",
    "display(df)\n",
    "\n",
    "# Create visualizations to analyze results\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Overall metrics by category\n",
    "category_scores = df.groupby('category').mean()\n",
    "category_scores.plot(kind='bar', figsize=(12, 6), title='Average Scores by Category')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylim(0, 5)  # Assuming scores are on a 0-5 scale\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create radar charts for each category\n",
    "categories = df['category'].unique()\n",
    "metrics = ['groundedness', 'relevance', 'coherence', 'fluency', 'helpfulness', 'friendliness', 'conciseness', 'accuracy']\n",
    "metrics = [m for m in metrics if m in df.columns]\n",
    "\n",
    "# Function to create a radar chart\n",
    "def create_radar_chart(category_data, title):\n",
    "    # Number of variables\n",
    "    N = len(metrics)\n",
    "    \n",
    "    # What will be the angle of each axis in the plot (divide the plot / number of variables)\n",
    "    angles = [n / float(N) * 2 * 3.14159 for n in range(N)]\n",
    "    angles += angles[:1]  # Close the loop\n",
    "    \n",
    "    # Get the values\n",
    "    values = category_data[metrics].mean().values.flatten().tolist()\n",
    "    values += values[:1]  # Close the loop\n",
    "    \n",
    "    # Create the plot\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax = plt.subplot(111, polar=True)\n",
    "    \n",
    "    # Draw one axis per variable and add labels\n",
    "    plt.xticks(angles[:-1], metrics, size=12)\n",
    "    \n",
    "    # Draw the chart\n",
    "    ax.plot(angles, values, linewidth=2, linestyle='solid')\n",
    "    ax.fill(angles, values, alpha=0.1)\n",
    "    \n",
    "    # Set y-axis limits\n",
    "    plt.ylim(0, 5)\n",
    "    \n",
    "    # Add title\n",
    "    plt.title(title, size=15)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create radar charts for overall and each category\n",
    "create_radar_chart(df, 'Overall Performance')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "for category in categories:\n",
    "    category_data = df[df['category'] == category]\n",
    "    create_radar_chart(category_data, f'Performance: {category} questions')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26584fd1",
   "metadata": {},
   "source": [
    "## Generate Insights and Recommendations\n",
    "\n",
    "Based on the evaluation results, let's generate insights and recommendations for improving the PyCon assistant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62ba167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate insights using Azure OpenAI\n",
    "def generate_insights(eval_results, metrics_df):\n",
    "    try:\n",
    "        # Format the data for analysis\n",
    "        metrics_str = metrics_df.to_string()\n",
    "        aggregate = json.dumps(eval_results[\"metrics\"], indent=2)\n",
    "        \n",
    "        insight_prompt = f\"\"\"\n",
    "        You are an expert in analyzing AI assistant evaluation results. Please analyze the following evaluation \n",
    "        results for a PyCon conference assistant and provide insights and recommendations.\n",
    "        \n",
    "        Evaluation Metrics by Query:\n",
    "        {metrics_str}\n",
    "        \n",
    "        Aggregate Metrics:\n",
    "        {aggregate}\n",
    "        \n",
    "        Please provide:\n",
    "        1. Key strengths (3-5 bullet points)\n",
    "        2. Areas for improvement (3-5 bullet points)\n",
    "        3. Specific recommendations to enhance the assistant's performance\n",
    "        4. Any patterns you notice across different question categories\n",
    "        \n",
    "        Format your response in Markdown with clear sections and bullet points.\n",
    "        \"\"\"\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=model_config[\"deployment_name\"],\n",
    "            messages=[{\"role\": \"user\", \"content\": insight_prompt}],\n",
    "            temperature=0.3,\n",
    "            max_tokens=1000\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating insights: {e}\")\n",
    "        return \"Error generating insights. Please check the evaluation results manually.\"\n",
    "\n",
    "# Generate and display insights\n",
    "insights = generate_insights(eval_results, df)\n",
    "print(insights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c935e2",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates how to evaluate a custom PyCon assistant copilot using the Azure AI Evaluation SDK. We've shown how to:\n",
    "\n",
    "1. Define a PyCon-specific system prompt to create a specialized assistant\n",
    "2. Create a test dataset with conference-specific questions\n",
    "3. Use built-in evaluators to assess basic quality metrics (groundedness, relevance, etc.)\n",
    "4. Create custom evaluators specifically designed for conference assistants\n",
    "5. Run comprehensive evaluations across different question categories\n",
    "6. Analyze results to identify strengths and areas for improvement\n",
    "7. Generate insights and recommendations for enhancing the assistant\n",
    "\n",
    "This evaluation framework can be extended to evaluate other types of specialized assistants by:\n",
    "- Modifying the system prompt for different domains\n",
    "- Creating domain-specific test datasets\n",
    "- Adding custom evaluators tailored to domain requirements\n",
    "- Adjusting analysis to focus on domain-specific performance metrics\n",
    "\n",
    "The Azure AI Evaluation SDK provides a powerful and flexible framework for evaluating and improving AI assistants across various specialized domains."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
