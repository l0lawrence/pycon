{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dd05314",
   "metadata": {},
   "source": [
    "# Evaluating a PyCon Assistant Copilot using Azure AI Evaluation SDK\n",
    "\n",
    "This notebook demonstrates how to evaluate a custom copilot that acts as a PyCon conference assistant using the Azure AI Evaluation SDK. We'll set up evaluation datasets, define custom evaluation criteria, and analyze the assistant's responses for quality, relevance, and helpfulness in the context of Python conference information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b60cbc4",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "First, let's install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "390b1669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-ai-evaluation in ./.venv/lib/python3.11/site-packages (1.5.0)\n",
      "Requirement already satisfied: azure-identity in ./.venv/lib/python3.11/site-packages (1.21.0)\n",
      "Requirement already satisfied: openai in ./.venv/lib/python3.11/site-packages (1.76.1)\n",
      "Collecting azure_ai_projects\n",
      "Collecting azure_ai_projects\n",
      "  Downloading azure_ai_projects-1.0.0b10-py3-none-any.whl.metadata (16 kB)\n",
      "  Downloading azure_ai_projects-1.0.0b10-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: promptflow-devkit>=1.17.1 in ./.venv/lib/python3.11/site-packages (from azure-ai-evaluation) (1.17.2)\n",
      "Requirement already satisfied: promptflow-core>=1.17.1 in ./.venv/lib/python3.11/site-packages (from azure-ai-evaluation) (1.17.2)\n",
      "Requirement already satisfied: pyjwt>=2.8.0 in ./.venv/lib/python3.11/site-packages (from azure-ai-evaluation) (2.10.1)\n",
      "Requirement already satisfied: azure-core>=1.30.2 in ./.venv/lib/python3.11/site-packages (from azure-ai-evaluation) (1.33.0)\n",
      "Requirement already satisfied: nltk>=3.9.1 in ./.venv/lib/python3.11/site-packages (from azure-ai-evaluation) (3.9.1)\n",
      "Requirement already satisfied: azure-storage-blob>=12.10.0 in ./.venv/lib/python3.11/site-packages (from azure-ai-evaluation) (12.25.1)\n",
      "Requirement already satisfied: httpx>=0.25.1 in ./.venv/lib/python3.11/site-packages (from azure-ai-evaluation) (0.28.1)\n",
      "Requirement already satisfied: pandas<3.0.0,>=2.1.2 in ./.venv/lib/python3.11/site-packages (from azure-ai-evaluation) (2.2.3)\n",
      "Requirement already satisfied: ruamel.yaml<1.0.0,>=0.17.10 in ./.venv/lib/python3.11/site-packages (from azure-ai-evaluation) (0.18.10)\n",
      "Requirement already satisfied: msrest>=0.6.21 in ./.venv/lib/python3.11/site-packages (from azure-ai-evaluation) (0.7.1)\n",
      "Requirement already satisfied: numpy>=1.23.2 in ./.venv/lib/python3.11/site-packages (from pandas<3.0.0,>=2.1.2->azure-ai-evaluation) (2.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.11/site-packages (from pandas<3.0.0,>=2.1.2->azure-ai-evaluation) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.11/site-packages (from pandas<3.0.0,>=2.1.2->azure-ai-evaluation) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.11/site-packages (from pandas<3.0.0,>=2.1.2->azure-ai-evaluation) (2025.2)\n",
      "Requirement already satisfied: promptflow-devkit>=1.17.1 in ./.venv/lib/python3.11/site-packages (from azure-ai-evaluation) (1.17.2)\n",
      "Requirement already satisfied: promptflow-core>=1.17.1 in ./.venv/lib/python3.11/site-packages (from azure-ai-evaluation) (1.17.2)\n",
      "Requirement already satisfied: pyjwt>=2.8.0 in ./.venv/lib/python3.11/site-packages (from azure-ai-evaluation) (2.10.1)\n",
      "Requirement already satisfied: azure-core>=1.30.2 in ./.venv/lib/python3.11/site-packages (from azure-ai-evaluation) (1.33.0)\n",
      "Requirement already satisfied: nltk>=3.9.1 in ./.venv/lib/python3.11/site-packages (from azure-ai-evaluation) (3.9.1)\n",
      "Requirement already satisfied: azure-storage-blob>=12.10.0 in ./.venv/lib/python3.11/site-packages (from azure-ai-evaluation) (12.25.1)\n",
      "Requirement already satisfied: httpx>=0.25.1 in ./.venv/lib/python3.11/site-packages (from azure-ai-evaluation) (0.28.1)\n",
      "Requirement already satisfied: pandas<3.0.0,>=2.1.2 in ./.venv/lib/python3.11/site-packages (from azure-ai-evaluation) (2.2.3)\n",
      "Requirement already satisfied: ruamel.yaml<1.0.0,>=0.17.10 in ./.venv/lib/python3.11/site-packages (from azure-ai-evaluation) (0.18.10)\n",
      "Requirement already satisfied: msrest>=0.6.21 in ./.venv/lib/python3.11/site-packages (from azure-ai-evaluation) (0.7.1)\n",
      "Requirement already satisfied: numpy>=1.23.2 in ./.venv/lib/python3.11/site-packages (from pandas<3.0.0,>=2.1.2->azure-ai-evaluation) (2.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.11/site-packages (from pandas<3.0.0,>=2.1.2->azure-ai-evaluation) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.11/site-packages (from pandas<3.0.0,>=2.1.2->azure-ai-evaluation) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.11/site-packages (from pandas<3.0.0,>=2.1.2->azure-ai-evaluation) (2025.2)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in ./.venv/lib/python3.11/site-packages (from ruamel.yaml<1.0.0,>=0.17.10->azure-ai-evaluation) (0.2.12)\n",
      "Requirement already satisfied: cryptography>=2.5 in ./.venv/lib/python3.11/site-packages (from azure-identity) (44.0.2)\n",
      "Requirement already satisfied: msal>=1.30.0 in ./.venv/lib/python3.11/site-packages (from azure-identity) (1.32.3)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in ./.venv/lib/python3.11/site-packages (from azure-identity) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in ./.venv/lib/python3.11/site-packages (from azure-identity) (4.13.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.11/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./.venv/lib/python3.11/site-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./.venv/lib/python3.11/site-packages (from openai) (2.11.3)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.11/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./.venv/lib/python3.11/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: idna>=2.8 in ./.venv/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.11/site-packages (from httpx>=0.25.1->azure-ai-evaluation) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.11/site-packages (from httpx>=0.25.1->azure-ai-evaluation) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.25.1->azure-ai-evaluation) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
      "Requirement already satisfied: isodate>=0.6.1 in ./.venv/lib/python3.11/site-packages (from azure_ai_projects) (0.7.2)\n",
      "Requirement already satisfied: requests>=2.21.0 in ./.venv/lib/python3.11/site-packages (from azure-core>=1.30.2->azure-ai-evaluation) (2.32.3)\n",
      "Requirement already satisfied: six>=1.11.0 in ./.venv/lib/python3.11/site-packages (from azure-core>=1.30.2->azure-ai-evaluation) (1.17.0)\n",
      "Requirement already satisfied: cffi>=1.12 in ./.venv/lib/python3.11/site-packages (from cryptography>=2.5->azure-identity) (1.17.1)\n",
      "Requirement already satisfied: pycparser in ./.venv/lib/python3.11/site-packages (from cffi>=1.12->cryptography>=2.5->azure-identity) (2.22)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in ./.venv/lib/python3.11/site-packages (from ruamel.yaml<1.0.0,>=0.17.10->azure-ai-evaluation) (0.2.12)\n",
      "Requirement already satisfied: cryptography>=2.5 in ./.venv/lib/python3.11/site-packages (from azure-identity) (44.0.2)\n",
      "Requirement already satisfied: msal>=1.30.0 in ./.venv/lib/python3.11/site-packages (from azure-identity) (1.32.3)\n",
      "Requirement already satisfied: msal-extensions>=1.2.0 in ./.venv/lib/python3.11/site-packages (from azure-identity) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in ./.venv/lib/python3.11/site-packages (from azure-identity) (4.13.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.11/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./.venv/lib/python3.11/site-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in ./.venv/lib/python3.11/site-packages (from openai) (2.11.3)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.11/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./.venv/lib/python3.11/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: idna>=2.8 in ./.venv/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.11/site-packages (from httpx>=0.25.1->azure-ai-evaluation) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.11/site-packages (from httpx>=0.25.1->azure-ai-evaluation) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in ./.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.25.1->azure-ai-evaluation) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
      "Requirement already satisfied: isodate>=0.6.1 in ./.venv/lib/python3.11/site-packages (from azure_ai_projects) (0.7.2)\n",
      "Requirement already satisfied: requests>=2.21.0 in ./.venv/lib/python3.11/site-packages (from azure-core>=1.30.2->azure-ai-evaluation) (2.32.3)\n",
      "Requirement already satisfied: six>=1.11.0 in ./.venv/lib/python3.11/site-packages (from azure-core>=1.30.2->azure-ai-evaluation) (1.17.0)\n",
      "Requirement already satisfied: cffi>=1.12 in ./.venv/lib/python3.11/site-packages (from cryptography>=2.5->azure-identity) (1.17.1)\n",
      "Requirement already satisfied: pycparser in ./.venv/lib/python3.11/site-packages (from cffi>=1.12->cryptography>=2.5->azure-identity) (2.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests>=2.21.0->azure-core>=1.30.2->azure-ai-evaluation) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests>=2.21.0->azure-core>=1.30.2->azure-ai-evaluation) (2.4.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in ./.venv/lib/python3.11/site-packages (from msrest>=0.6.21->azure-ai-evaluation) (2.0.0)\n",
      "Requirement already satisfied: click in ./.venv/lib/python3.11/site-packages (from nltk>=3.9.1->azure-ai-evaluation) (8.1.8)\n",
      "Requirement already satisfied: joblib in ./.venv/lib/python3.11/site-packages (from nltk>=3.9.1->azure-ai-evaluation) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./.venv/lib/python3.11/site-packages (from nltk>=3.9.1->azure-ai-evaluation) (2024.11.6)\n",
      "Requirement already satisfied: docstring_parser in ./.venv/lib/python3.11/site-packages (from promptflow-core>=1.17.1->azure-ai-evaluation) (0.16)\n",
      "Requirement already satisfied: fastapi<1.0.0,>=0.109.0 in ./.venv/lib/python3.11/site-packages (from promptflow-core>=1.17.1->azure-ai-evaluation) (0.115.12)\n",
      "Requirement already satisfied: filetype>=1.2.0 in ./.venv/lib/python3.11/site-packages (from promptflow-core>=1.17.1->azure-ai-evaluation) (1.2.0)\n",
      "Requirement already satisfied: flask<4.0.0,>=2.2.3 in ./.venv/lib/python3.11/site-packages (from promptflow-core>=1.17.1->azure-ai-evaluation) (3.1.0)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in ./.venv/lib/python3.11/site-packages (from promptflow-core>=1.17.1->azure-ai-evaluation) (4.23.0)\n",
      "Requirement already satisfied: promptflow-tracing==1.17.2 in ./.venv/lib/python3.11/site-packages (from promptflow-core>=1.17.1->azure-ai-evaluation) (1.17.2)\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.11/site-packages (from promptflow-core>=1.17.1->azure-ai-evaluation) (6.1.1)\n",
      "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.22.0 in ./.venv/lib/python3.11/site-packages (from promptflow-tracing==1.17.2->promptflow-core>=1.17.1->azure-ai-evaluation) (1.32.1)\n",
      "Requirement already satisfied: tiktoken>=0.4.0 in ./.venv/lib/python3.11/site-packages (from promptflow-tracing==1.17.2->promptflow-core>=1.17.1->azure-ai-evaluation) (0.9.0)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in ./.venv/lib/python3.11/site-packages (from fastapi<1.0.0,>=0.109.0->promptflow-core>=1.17.1->azure-ai-evaluation) (0.46.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests>=2.21.0->azure-core>=1.30.2->azure-ai-evaluation) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests>=2.21.0->azure-core>=1.30.2->azure-ai-evaluation) (2.4.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in ./.venv/lib/python3.11/site-packages (from msrest>=0.6.21->azure-ai-evaluation) (2.0.0)\n",
      "Requirement already satisfied: click in ./.venv/lib/python3.11/site-packages (from nltk>=3.9.1->azure-ai-evaluation) (8.1.8)\n",
      "Requirement already satisfied: joblib in ./.venv/lib/python3.11/site-packages (from nltk>=3.9.1->azure-ai-evaluation) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./.venv/lib/python3.11/site-packages (from nltk>=3.9.1->azure-ai-evaluation) (2024.11.6)\n",
      "Requirement already satisfied: docstring_parser in ./.venv/lib/python3.11/site-packages (from promptflow-core>=1.17.1->azure-ai-evaluation) (0.16)\n",
      "Requirement already satisfied: fastapi<1.0.0,>=0.109.0 in ./.venv/lib/python3.11/site-packages (from promptflow-core>=1.17.1->azure-ai-evaluation) (0.115.12)\n",
      "Requirement already satisfied: filetype>=1.2.0 in ./.venv/lib/python3.11/site-packages (from promptflow-core>=1.17.1->azure-ai-evaluation) (1.2.0)\n",
      "Requirement already satisfied: flask<4.0.0,>=2.2.3 in ./.venv/lib/python3.11/site-packages (from promptflow-core>=1.17.1->azure-ai-evaluation) (3.1.0)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in ./.venv/lib/python3.11/site-packages (from promptflow-core>=1.17.1->azure-ai-evaluation) (4.23.0)\n",
      "Requirement already satisfied: promptflow-tracing==1.17.2 in ./.venv/lib/python3.11/site-packages (from promptflow-core>=1.17.1->azure-ai-evaluation) (1.17.2)\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.11/site-packages (from promptflow-core>=1.17.1->azure-ai-evaluation) (6.1.1)\n",
      "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.22.0 in ./.venv/lib/python3.11/site-packages (from promptflow-tracing==1.17.2->promptflow-core>=1.17.1->azure-ai-evaluation) (1.32.1)\n",
      "Requirement already satisfied: tiktoken>=0.4.0 in ./.venv/lib/python3.11/site-packages (from promptflow-tracing==1.17.2->promptflow-core>=1.17.1->azure-ai-evaluation) (0.9.0)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in ./.venv/lib/python3.11/site-packages (from fastapi<1.0.0,>=0.109.0->promptflow-core>=1.17.1->azure-ai-evaluation) (0.46.2)\n",
      "Requirement already satisfied: Werkzeug>=3.1 in ./.venv/lib/python3.11/site-packages (from flask<4.0.0,>=2.2.3->promptflow-core>=1.17.1->azure-ai-evaluation) (3.1.3)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in ./.venv/lib/python3.11/site-packages (from flask<4.0.0,>=2.2.3->promptflow-core>=1.17.1->azure-ai-evaluation) (3.1.6)\n",
      "Requirement already satisfied: itsdangerous>=2.2 in ./.venv/lib/python3.11/site-packages (from flask<4.0.0,>=2.2.3->promptflow-core>=1.17.1->azure-ai-evaluation) (2.2.0)\n",
      "Requirement already satisfied: blinker>=1.9 in ./.venv/lib/python3.11/site-packages (from flask<4.0.0,>=2.2.3->promptflow-core>=1.17.1->azure-ai-evaluation) (1.9.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in ./.venv/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.0.0->promptflow-core>=1.17.1->azure-ai-evaluation) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./.venv/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.0.0->promptflow-core>=1.17.1->azure-ai-evaluation) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./.venv/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.0.0->promptflow-core>=1.17.1->azure-ai-evaluation) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./.venv/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.0.0->promptflow-core>=1.17.1->azure-ai-evaluation) (0.24.0)\n",
      "Requirement already satisfied: opentelemetry-api==1.32.1 in ./.venv/lib/python3.11/site-packages (from opentelemetry-sdk<2.0.0,>=1.22.0->promptflow-tracing==1.17.2->promptflow-core>=1.17.1->azure-ai-evaluation) (1.32.1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.53b1 in ./.venv/lib/python3.11/site-packages (from opentelemetry-sdk<2.0.0,>=1.22.0->promptflow-tracing==1.17.2->promptflow-core>=1.17.1->azure-ai-evaluation) (0.53b1)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in ./.venv/lib/python3.11/site-packages (from opentelemetry-api==1.32.1->opentelemetry-sdk<2.0.0,>=1.22.0->promptflow-tracing==1.17.2->promptflow-core>=1.17.1->azure-ai-evaluation) (1.2.18)\n",
      "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in ./.venv/lib/python3.11/site-packages (from opentelemetry-api==1.32.1->opentelemetry-sdk<2.0.0,>=1.22.0->promptflow-tracing==1.17.2->promptflow-core>=1.17.1->azure-ai-evaluation) (8.6.1)\n",
      "Requirement already satisfied: zipp>=3.20 in ./.venv/lib/python3.11/site-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api==1.32.1->opentelemetry-sdk<2.0.0,>=1.22.0->promptflow-tracing==1.17.2->promptflow-core>=1.17.1->azure-ai-evaluation) (3.21.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in ./.venv/lib/python3.11/site-packages (from deprecated>=1.2.6->opentelemetry-api==1.32.1->opentelemetry-sdk<2.0.0,>=1.22.0->promptflow-tracing==1.17.2->promptflow-core>=1.17.1->azure-ai-evaluation) (1.17.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.11/site-packages (from Jinja2>=3.1.2->flask<4.0.0,>=2.2.3->promptflow-core>=1.17.1->azure-ai-evaluation) (3.0.2)\n",
      "Requirement already satisfied: argcomplete>=3.2.3 in ./.venv/lib/python3.11/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (3.6.2)\n",
      "Requirement already satisfied: azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21 in ./.venv/lib/python3.11/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (1.0.0b36)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.6 in ./.venv/lib/python3.11/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (0.4.6)\n",
      "Requirement already satisfied: filelock<4.0.0,>=3.4.0 in ./.venv/lib/python3.11/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (3.18.0)\n",
      "Requirement already satisfied: flask-cors<6.0.0,>=5.0.0 in ./.venv/lib/python3.11/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (5.0.1)\n",
      "Requirement already satisfied: flask-restx<2.0.0,>=1.2.0 in ./.venv/lib/python3.11/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (1.3.0)\n",
      "Requirement already satisfied: gitpython<4.0.0,>=3.1.24 in ./.venv/lib/python3.11/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (3.1.44)\n",
      "Requirement already satisfied: keyring<25.0.0,>=24.2.0 in ./.venv/lib/python3.11/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (24.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.5 in ./.venv/lib/python3.11/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (3.26.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0 in ./.venv/lib/python3.11/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (1.32.1)\n",
      "Requirement already satisfied: pillow<11.1.0,>=10.1.0 in ./.venv/lib/python3.11/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (11.0.0)\n",
      "Requirement already satisfied: pydash<8.0.0,>=6.0.0 in ./.venv/lib/python3.11/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (7.0.7)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.0 in ./.venv/lib/python3.11/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (1.1.0)\n",
      "Requirement already satisfied: sqlalchemy<3.0.0,>=1.4.48 in ./.venv/lib/python3.11/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (2.0.40)\n",
      "Requirement already satisfied: strictyaml<2.0.0,>=1.5.0 in ./.venv/lib/python3.11/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (1.7.3)\n",
      "Requirement already satisfied: tabulate<1.0.0,>=0.9.0 in ./.venv/lib/python3.11/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (0.9.0)\n",
      "Requirement already satisfied: waitress<4.0.0,>=3.0.0 in ./.venv/lib/python3.11/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (3.0.2)\n",
      "Requirement already satisfied: Werkzeug>=3.1 in ./.venv/lib/python3.11/site-packages (from flask<4.0.0,>=2.2.3->promptflow-core>=1.17.1->azure-ai-evaluation) (3.1.3)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in ./.venv/lib/python3.11/site-packages (from flask<4.0.0,>=2.2.3->promptflow-core>=1.17.1->azure-ai-evaluation) (3.1.6)\n",
      "Requirement already satisfied: itsdangerous>=2.2 in ./.venv/lib/python3.11/site-packages (from flask<4.0.0,>=2.2.3->promptflow-core>=1.17.1->azure-ai-evaluation) (2.2.0)\n",
      "Requirement already satisfied: blinker>=1.9 in ./.venv/lib/python3.11/site-packages (from flask<4.0.0,>=2.2.3->promptflow-core>=1.17.1->azure-ai-evaluation) (1.9.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in ./.venv/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.0.0->promptflow-core>=1.17.1->azure-ai-evaluation) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in ./.venv/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.0.0->promptflow-core>=1.17.1->azure-ai-evaluation) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in ./.venv/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.0.0->promptflow-core>=1.17.1->azure-ai-evaluation) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in ./.venv/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.0.0->promptflow-core>=1.17.1->azure-ai-evaluation) (0.24.0)\n",
      "Requirement already satisfied: opentelemetry-api==1.32.1 in ./.venv/lib/python3.11/site-packages (from opentelemetry-sdk<2.0.0,>=1.22.0->promptflow-tracing==1.17.2->promptflow-core>=1.17.1->azure-ai-evaluation) (1.32.1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.53b1 in ./.venv/lib/python3.11/site-packages (from opentelemetry-sdk<2.0.0,>=1.22.0->promptflow-tracing==1.17.2->promptflow-core>=1.17.1->azure-ai-evaluation) (0.53b1)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in ./.venv/lib/python3.11/site-packages (from opentelemetry-api==1.32.1->opentelemetry-sdk<2.0.0,>=1.22.0->promptflow-tracing==1.17.2->promptflow-core>=1.17.1->azure-ai-evaluation) (1.2.18)\n",
      "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in ./.venv/lib/python3.11/site-packages (from opentelemetry-api==1.32.1->opentelemetry-sdk<2.0.0,>=1.22.0->promptflow-tracing==1.17.2->promptflow-core>=1.17.1->azure-ai-evaluation) (8.6.1)\n",
      "Requirement already satisfied: zipp>=3.20 in ./.venv/lib/python3.11/site-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api==1.32.1->opentelemetry-sdk<2.0.0,>=1.22.0->promptflow-tracing==1.17.2->promptflow-core>=1.17.1->azure-ai-evaluation) (3.21.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in ./.venv/lib/python3.11/site-packages (from deprecated>=1.2.6->opentelemetry-api==1.32.1->opentelemetry-sdk<2.0.0,>=1.22.0->promptflow-tracing==1.17.2->promptflow-core>=1.17.1->azure-ai-evaluation) (1.17.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.11/site-packages (from Jinja2>=3.1.2->flask<4.0.0,>=2.2.3->promptflow-core>=1.17.1->azure-ai-evaluation) (3.0.2)\n",
      "Requirement already satisfied: argcomplete>=3.2.3 in ./.venv/lib/python3.11/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (3.6.2)\n",
      "Requirement already satisfied: azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21 in ./.venv/lib/python3.11/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (1.0.0b36)\n",
      "Requirement already satisfied: colorama<0.5.0,>=0.4.6 in ./.venv/lib/python3.11/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (0.4.6)\n",
      "Requirement already satisfied: filelock<4.0.0,>=3.4.0 in ./.venv/lib/python3.11/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (3.18.0)\n",
      "Requirement already satisfied: flask-cors<6.0.0,>=5.0.0 in ./.venv/lib/python3.11/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (5.0.1)\n",
      "Requirement already satisfied: flask-restx<2.0.0,>=1.2.0 in ./.venv/lib/python3.11/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (1.3.0)\n",
      "Requirement already satisfied: gitpython<4.0.0,>=3.1.24 in ./.venv/lib/python3.11/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (3.1.44)\n",
      "Requirement already satisfied: keyring<25.0.0,>=24.2.0 in ./.venv/lib/python3.11/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (24.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.5 in ./.venv/lib/python3.11/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (3.26.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0 in ./.venv/lib/python3.11/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (1.32.1)\n",
      "Requirement already satisfied: pillow<11.1.0,>=10.1.0 in ./.venv/lib/python3.11/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (11.0.0)\n",
      "Requirement already satisfied: pydash<8.0.0,>=6.0.0 in ./.venv/lib/python3.11/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (7.0.7)\n",
      "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.0 in ./.venv/lib/python3.11/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (1.1.0)\n",
      "Requirement already satisfied: sqlalchemy<3.0.0,>=1.4.48 in ./.venv/lib/python3.11/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (2.0.40)\n",
      "Requirement already satisfied: strictyaml<2.0.0,>=1.5.0 in ./.venv/lib/python3.11/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (1.7.3)\n",
      "Requirement already satisfied: tabulate<1.0.0,>=0.9.0 in ./.venv/lib/python3.11/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (0.9.0)\n",
      "Requirement already satisfied: waitress<4.0.0,>=3.0.0 in ./.venv/lib/python3.11/site-packages (from promptflow-devkit>=1.17.1->azure-ai-evaluation) (3.0.2)\n",
      "Requirement already satisfied: fixedint==0.1.6 in ./.venv/lib/python3.11/site-packages (from azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit>=1.17.1->azure-ai-evaluation) (0.1.6)\n",
      "Requirement already satisfied: aniso8601>=0.82 in ./.venv/lib/python3.11/site-packages (from flask-restx<2.0.0,>=1.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (10.0.1)\n",
      "Requirement already satisfied: importlib-resources in ./.venv/lib/python3.11/site-packages (from flask-restx<2.0.0,>=1.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (6.5.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in ./.venv/lib/python3.11/site-packages (from gitpython<4.0.0,>=3.1.24->promptflow-devkit>=1.17.1->azure-ai-evaluation) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in ./.venv/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython<4.0.0,>=3.1.24->promptflow-devkit>=1.17.1->azure-ai-evaluation) (5.0.2)\n",
      "Requirement already satisfied: jaraco.classes in ./.venv/lib/python3.11/site-packages (from keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (3.4.0)\n",
      "Requirement already satisfied: SecretStorage>=3.2 in ./.venv/lib/python3.11/site-packages (from keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (3.3.3)\n",
      "Requirement already satisfied: jeepney>=0.4.2 in ./.venv/lib/python3.11/site-packages (from keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (0.9.0)\n",
      "Requirement already satisfied: packaging>=17.0 in ./.venv/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.5->promptflow-devkit>=1.17.1->azure-ai-evaluation) (25.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in ./.venv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.32.1 in ./.venv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (1.32.1)\n",
      "Requirement already satisfied: opentelemetry-proto==1.32.1 in ./.venv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (1.32.1)\n",
      "Requirement already satisfied: protobuf<6.0,>=5.0 in ./.venv/lib/python3.11/site-packages (from opentelemetry-proto==1.32.1->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (5.29.4)\n",
      "Requirement already satisfied: fixedint==0.1.6 in ./.venv/lib/python3.11/site-packages (from azure-monitor-opentelemetry-exporter<2.0.0,>=1.0.0b21->promptflow-devkit>=1.17.1->azure-ai-evaluation) (0.1.6)\n",
      "Requirement already satisfied: aniso8601>=0.82 in ./.venv/lib/python3.11/site-packages (from flask-restx<2.0.0,>=1.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (10.0.1)\n",
      "Requirement already satisfied: importlib-resources in ./.venv/lib/python3.11/site-packages (from flask-restx<2.0.0,>=1.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (6.5.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in ./.venv/lib/python3.11/site-packages (from gitpython<4.0.0,>=3.1.24->promptflow-devkit>=1.17.1->azure-ai-evaluation) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in ./.venv/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython<4.0.0,>=3.1.24->promptflow-devkit>=1.17.1->azure-ai-evaluation) (5.0.2)\n",
      "Requirement already satisfied: jaraco.classes in ./.venv/lib/python3.11/site-packages (from keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (3.4.0)\n",
      "Requirement already satisfied: SecretStorage>=3.2 in ./.venv/lib/python3.11/site-packages (from keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (3.3.3)\n",
      "Requirement already satisfied: jeepney>=0.4.2 in ./.venv/lib/python3.11/site-packages (from keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (0.9.0)\n",
      "Requirement already satisfied: packaging>=17.0 in ./.venv/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.5->promptflow-devkit>=1.17.1->azure-ai-evaluation) (25.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in ./.venv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.32.1 in ./.venv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (1.32.1)\n",
      "Requirement already satisfied: opentelemetry-proto==1.32.1 in ./.venv/lib/python3.11/site-packages (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (1.32.1)\n",
      "Requirement already satisfied: protobuf<6.0,>=5.0 in ./.venv/lib/python3.11/site-packages (from opentelemetry-proto==1.32.1->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.22.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (5.29.4)\n",
      "Requirement already satisfied: greenlet>=1 in ./.venv/lib/python3.11/site-packages (from sqlalchemy<3.0.0,>=1.4.48->promptflow-devkit>=1.17.1->azure-ai-evaluation) (3.2.1)\n",
      "Requirement already satisfied: greenlet>=1 in ./.venv/lib/python3.11/site-packages (from sqlalchemy<3.0.0,>=1.4.48->promptflow-devkit>=1.17.1->azure-ai-evaluation) (3.2.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./.venv/lib/python3.11/site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.21->azure-ai-evaluation) (3.2.2)\n",
      "Requirement already satisfied: more-itertools in ./.venv/lib/python3.11/site-packages (from jaraco.classes->keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (10.7.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./.venv/lib/python3.11/site-packages (from requests-oauthlib>=0.5.0->msrest>=0.6.21->azure-ai-evaluation) (3.2.2)\n",
      "Requirement already satisfied: more-itertools in ./.venv/lib/python3.11/site-packages (from jaraco.classes->keyring<25.0.0,>=24.2.0->promptflow-devkit>=1.17.1->azure-ai-evaluation) (10.7.0)\n",
      "Downloading azure_ai_projects-1.0.0b10-py3-none-any.whl (200 kB)\n",
      "Downloading azure_ai_projects-1.0.0b10-py3-none-any.whl (200 kB)\n",
      "Installing collected packages: azure_ai_projects\n",
      "Installing collected packages: azure_ai_projects\n",
      "Successfully installed azure_ai_projects-1.0.0b10\n",
      "Successfully installed azure_ai_projects-1.0.0b10\n"
     ]
    }
   ],
   "source": [
    "# Install the Azure AI Evaluation SDK and other required packages\n",
    "!pip install azure-ai-evaluation azure-identity openai azure_ai_projects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceece0eb",
   "metadata": {},
   "source": [
    "## Setup and Configuration\n",
    "\n",
    "Let's set up our environment variables and authentication for Azure services:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8794e798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded environment variables from .env file\n",
      "✅ All required environment variables are set!\n",
      "✅ Successfully initialized Azure OpenAI client\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "# Load environment variables from .env file\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    # Load .env file if it exists\n",
    "    load_dotenv()\n",
    "    print(\"✅ Loaded environment variables from .env file\")\n",
    "except ImportError:\n",
    "    print(\"⚠️ python-dotenv not installed. Install with: pip install python-dotenv\")\n",
    "    print(\"  Using environment variables directly from system.\")\n",
    "\n",
    "# Set up authentication - prefer DefaultAzureCredential for managed identity support\n",
    "credential = DefaultAzureCredential()\n",
    "\n",
    "# Initialize Azure AI project configuration\n",
    "azure_ai_project = {\n",
    "    \"subscription_id\": os.getenv(\"AZURE_SUBSCRIPTION_ID\"),\n",
    "    \"resource_group_name\": os.getenv(\"AZURE_RESOURCE_GROUP\"),\n",
    "    \"project_name\": os.getenv(\"AZURE_PROJECT_NAME\"),\n",
    "}\n",
    "\n",
    "# Model configuration for evaluators that use LLMs\n",
    "model_config = {\n",
    "    \"azure_endpoint\": os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    \"api_key\": os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    \"api_version\": os.getenv(\"AZURE_OPENAI_API_VERSION\", \"2023-12-01-preview\"),\n",
    "    \"azure_deployment\": os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "}\n",
    "\n",
    "# Validate configuration\n",
    "missing_vars = []\n",
    "for config_dict, keys in [\n",
    "    (azure_ai_project, [\"subscription_id\", \"resource_group_name\", \"project_name\"]),\n",
    "    (model_config, [\"azure_endpoint\", \"api_key\", \"api_version\", \"azure_deployment\"]),\n",
    "]:\n",
    "    for key in keys:\n",
    "        if not config_dict.get(key):\n",
    "            missing_vars.append(key)\n",
    "\n",
    "if missing_vars:\n",
    "    print(f\"❌ Missing required environment variables: {', '.join(missing_vars)}\")\n",
    "    print(\"Please set these environment variables before running the notebook.\")\n",
    "    print(\"You can run setup_env.py to create a .env file with these variables.\")\n",
    "else:\n",
    "    print(\"✅ All required environment variables are set!\")\n",
    "\n",
    "# Initialize Azure OpenAI client for our assistant simulation\n",
    "try:\n",
    "    client = AzureOpenAI(\n",
    "        azure_endpoint=model_config[\"azure_endpoint\"],\n",
    "        api_key=model_config[\"api_key\"],\n",
    "        api_version=model_config[\"api_version\"]\n",
    "    )\n",
    "    print(\"✅ Successfully initialized Azure OpenAI client\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Failed to initialize Azure OpenAI client: {str(e)}\")\n",
    "    print(\"Please check your environment variables and Azure OpenAI configuration.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e2a342",
   "metadata": {},
   "source": [
    "## Define PyCon Assistant System Prompt\n",
    "\n",
    "Here we'll define the system prompt that turns a general LLM into a PyCon conference assistant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3353e5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "PYCON_ASSISTANT_SYSTEM_PROMPT = \"\"\"\n",
    "You are a helpful PyCon conference assistant. Your primary role is to assist conference attendees \n",
    "with information about the conference schedule, talks, workshops, speakers, and logistics. \n",
    "\n",
    "You have the following knowledge about PyCon 2025:\n",
    "- The conference is happening May 15-23, 2025 in Pittsburgh, PA\n",
    "- Main conference days are May 17-19, with tutorials on May 15-16 and sprints on May 20-23\n",
    "- Registration opens December 15, 2024 with early bird pricing until February 1, 2025\n",
    "- The venue is the David L. Lawrence Convention Center in downtown Pittsburgh\n",
    "- Keynote speakers include Guido van Rossum, Dr. Russell Keith-Magee, and Dr. Łukasz Langa\n",
    "- There are 95 scheduled talks across 5 parallel tracks, 30 tutorials, and 15 sponsored workshops\n",
    "- Conference themes include: AI/ML, Web Development, Data Science, Python Core, and Python in Education\n",
    "\n",
    "Important policies include:\n",
    "- All attendees must follow the conference Code of Conduct\n",
    "- Refunds available up to 30 days before the conference with a 10% processing fee\n",
    "- Limited financial aid is available through an application process that closes February 28, 2025\n",
    "\n",
    "Answer questions helpfully, accurately, and concisely. If you don't know an answer, acknowledge that \n",
    "and suggest where the attendee might find the information (e.g., the registration desk, conference website, etc.).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54716c32",
   "metadata": {},
   "source": [
    "## Create a PyCon Assistant Simulation\n",
    "\n",
    "We'll create a function that simulates our PyCon assistant by using the Azure OpenAI service with our system prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a67d6f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pycon_assistant(query):\n",
    "    \"\"\"Simulate a PyCon assistant by using Azure OpenAI with a specific system prompt\"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model_config[\"deployment_name\"],\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": PYCON_ASSISTANT_SYSTEM_PROMPT},\n",
    "                {\"role\": \"user\", \"content\": query}\n",
    "            ],\n",
    "            temperature=0.3,  # Lower temperature for more consistent answers\n",
    "            max_tokens=500\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error in pycon_assistant: {e}\")\n",
    "        return f\"Sorry, I encountered an error: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6499bf2f",
   "metadata": {},
   "source": [
    "## Create PyCon-Specific Test Dataset\n",
    "\n",
    "Now, let's create a dataset of PyCon-specific questions that we'll use to evaluate our assistant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29a47162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: When is PyCon 2025 happening?\n",
      "Response: PyCon 2025 is happening from May 15-23, 2025, in Pittsburgh, PA. The main conference days are May 17-19, with tutorials on May 15-16 and sprints on May 20-23.\n",
      "---\n",
      "Query: Who are the keynote speakers?\n",
      "Response: The keynote speakers for PyCon 2025 are Guido van Rossum, Dr. Russell Keith-Magee, and Dr. Łukasz Langa.\n",
      "---\n",
      "Query: How much does registration cost?\n",
      "Response: I don't have the exact registration pricing details, but I can tell you that registration opens on December 15, 2024, with early bird pricing available until February 1, 2025. For specific pricing information, I recommend checking the PyCon 2025 conference website or contacting the registration desk directly.\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Create test dataset with questions, relevant context, and expected answer patterns\n",
    "pycon_test_data = [\n",
    "    {\n",
    "        \"query\": \"When is PyCon 2025 happening?\",\n",
    "        \"context\": \"The conference is happening May 15-23, 2025 in Pittsburgh, PA.\",\n",
    "        \"expected_pattern\": \"May 15-23, 2025\",\n",
    "        \"category\": \"logistics\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Who are the keynote speakers?\",\n",
    "        \"context\": \"Keynote speakers include Guido van Rossum, Dr. Russell Keith-Magee, and Dr. Łukasz Langa.\",\n",
    "        \"expected_pattern\": \"Guido van Rossum|Russell Keith-Magee|Łukasz Langa\",\n",
    "        \"category\": \"speakers\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"How much does registration cost?\",\n",
    "        \"context\": \"Registration opens December 15, 2024 with early bird pricing until February 1, 2025.\",\n",
    "        \"expected_pattern\": \"\",  # No specific pricing was provided in system prompt\n",
    "        \"category\": \"registration\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Do you have a code of conduct?\",\n",
    "        \"context\": \"All attendees must follow the conference Code of Conduct.\",\n",
    "        \"expected_pattern\": \"Code of Conduct\",\n",
    "        \"category\": \"policy\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Can I get a refund if I can't attend?\",\n",
    "        \"context\": \"Refunds available up to 30 days before the conference with a 10% processing fee.\",\n",
    "        \"expected_pattern\": \"30 days|10%\",\n",
    "        \"category\": \"policy\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"How many tracks will the conference have?\",\n",
    "        \"context\": \"There are 95 scheduled talks across 5 parallel tracks, 30 tutorials, and 15 sponsored workshops.\",\n",
    "        \"expected_pattern\": \"5 parallel tracks|5 tracks\",\n",
    "        \"category\": \"schedule\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What topics will be covered at PyCon 2025?\",\n",
    "        \"context\": \"Conference themes include: AI/ML, Web Development, Data Science, Python Core, and Python in Education.\",\n",
    "        \"expected_pattern\": \"AI/ML|Web Development|Data Science|Python Core|Python in Education\",\n",
    "        \"category\": \"content\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Is there financial aid available?\",\n",
    "        \"context\": \"Limited financial aid is available through an application process that closes February 28, 2025.\",\n",
    "        \"expected_pattern\": \"financial aid|application|February 28\",\n",
    "        \"category\": \"logistics\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"Where exactly is the conference venue located?\",\n",
    "        \"context\": \"The venue is the David L. Lawrence Convention Center in downtown Pittsburgh.\",\n",
    "        \"expected_pattern\": \"David L. Lawrence Convention Center|downtown Pittsburgh\",\n",
    "        \"category\": \"logistics\"\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"When do the tutorial sessions happen?\",\n",
    "        \"context\": \"Main conference days are May 17-19, with tutorials on May 15-16 and sprints on May 20-23.\",\n",
    "        \"expected_pattern\": \"May 15-16\",\n",
    "        \"category\": \"schedule\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Generate responses from our PyCon assistant\n",
    "for item in pycon_test_data:\n",
    "    item[\"response\"] = pycon_assistant(item[\"query\"])\n",
    "\n",
    "# Save the sample data to a JSONL file\n",
    "with open(\"pycon_test_data.jsonl\", \"w\") as f:\n",
    "    for item in pycon_test_data:\n",
    "        f.write(json.dumps(item) + \"\\n\")\n",
    "\n",
    "# Display a few examples of the assistant's responses\n",
    "for i in range(3):  # Show first 3 examples\n",
    "    print(f\"Query: {pycon_test_data[i]['query']}\")\n",
    "    print(f\"Response: {pycon_test_data[i]['response']}\")\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ecb279",
   "metadata": {},
   "source": [
    "## Create Custom Evaluators for PyCon Assistant\n",
    "\n",
    "Now, let's create some custom evaluators specifically designed to evaluate a conference assistant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a53119f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from azure.ai.evaluation import (\n",
    "    GroundednessEvaluator,\n",
    "    RelevanceEvaluator,\n",
    "    CoherenceEvaluator,\n",
    "    FluencyEvaluator\n",
    ")\n",
    "\n",
    "# Initialize built-in evaluators\n",
    "groundedness_eval = GroundednessEvaluator(model_config)\n",
    "relevance_eval = RelevanceEvaluator(model_config)\n",
    "coherence_eval = CoherenceEvaluator(model_config)\n",
    "fluency_eval = FluencyEvaluator(model_config)\n",
    "\n",
    "# Create a simple custom evaluator to check if the response contains expected information\n",
    "class ExpectedPatternEvaluator:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, *, response: str, expected_pattern: str, **kwargs):\n",
    "        # If no pattern is provided, this test is not applicable\n",
    "        if not expected_pattern:\n",
    "            return {\n",
    "                \"value\": None,\n",
    "                \"reason\": \"No expected pattern provided for this query.\"\n",
    "            }\n",
    "        \n",
    "        # Check if the response contains any of the expected patterns (separated by |)\n",
    "        patterns = expected_pattern.split('|')\n",
    "        matches = [bool(re.search(pattern, response, re.IGNORECASE)) for pattern in patterns]\n",
    "        match_ratio = sum(matches) / len(patterns) if patterns else 0\n",
    "        \n",
    "        return {\n",
    "            \"value\": 1.0 if any(matches) else 0.0,  # Binary score: 1 if any pattern matches, 0 otherwise\n",
    "            \"match_ratio\": match_ratio,  # Proportion of patterns that matched\n",
    "            \"matched_patterns\": [patterns[i] for i, m in enumerate(matches) if m],\n",
    "            \"reason\": f\"Found {sum(matches)} of {len(patterns)} expected patterns in the response.\"\n",
    "        }\n",
    "\n",
    "# Create a custom evaluator for conference-specific tone and helpfulness\n",
    "class ConferenceAssistantEvaluator:\n",
    "    def __init__(self, model_config):\n",
    "        self.model_config = model_config\n",
    "        \n",
    "    def __call__(self, *, query: str, response: str, category: str, **kwargs):\n",
    "        # Use Azure OpenAI to evaluate the assistant's response\n",
    "        try:\n",
    "            eval_client = AzureOpenAI(\n",
    "                azure_endpoint=self.model_config[\"azure_endpoint\"],\n",
    "                api_key=self.model_config[\"api_key\"],\n",
    "                api_version=self.model_config[\"api_version\"]\n",
    "            )\n",
    "            \n",
    "            # Create an evaluation prompt\n",
    "            eval_prompt = f\"\"\"\n",
    "            Please evaluate the following response from a PyCon conference assistant based on the criteria below:\n",
    "            \n",
    "            Question: {query}\n",
    "            Response: {response}\n",
    "            Question Category: {category}\n",
    "            \n",
    "            Evaluate on a scale of 1-5 (where 5 is best) for each:\n",
    "            1. Helpfulness: Does it directly address the attendee's need?\n",
    "            2. Friendliness: Is the tone welcoming and appropriate for a conference assistant?\n",
    "            3. Conciseness: Is the answer appropriately brief while being complete?\n",
    "            4. Accuracy: Based on common knowledge about tech conferences (not specific PyCon details).\n",
    "            \n",
    "            Provide your scores and a brief 1-2 sentence rationale for each.\n",
    "            \n",
    "            Format your response as a JSON object with the following structure:\n",
    "            {{\n",
    "                \"helpfulness\": {{\"score\": [1-5], \"rationale\": \"your rationale\"}},\n",
    "                \"friendliness\": {{\"score\": [1-5], \"rationale\": \"your rationale\"}},\n",
    "                \"conciseness\": {{\"score\": [1-5], \"rationale\": \"your rationale\"}},\n",
    "                \"accuracy\": {{\"score\": [1-5], \"rationale\": \"your rationale\"}},\n",
    "                \"overall\": {{\"score\": [1-5], \"rationale\": \"your rationale\"}}  \n",
    "            }}\n",
    "            \"\"\"\n",
    "            \n",
    "            response = eval_client.chat.completions.create(\n",
    "                model=self.model_config[\"deployment_name\"],\n",
    "                messages=[{\"role\": \"user\", \"content\": eval_prompt}],\n",
    "                response_format={\"type\": \"json_object\"},\n",
    "                temperature=0.1\n",
    "            )\n",
    "            \n",
    "            # Parse and return the evaluation\n",
    "            result = json.loads(response.choices[0].message.content)\n",
    "            \n",
    "            # Calculate average score across all dimensions\n",
    "            scores = [result[key][\"score\"] for key in [\"helpfulness\", \"friendliness\", \"conciseness\", \"accuracy\"]]\n",
    "            result[\"average_score\"] = sum(scores) / len(scores)\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in ConferenceAssistantEvaluator: {e}\")\n",
    "            return {\n",
    "                \"error\": str(e),\n",
    "                \"helpfulness\": {\"score\": 0, \"rationale\": \"Evaluation failed\"},\n",
    "                \"friendliness\": {\"score\": 0, \"rationale\": \"Evaluation failed\"},\n",
    "                \"conciseness\": {\"score\": 0, \"rationale\": \"Evaluation failed\"},\n",
    "                \"accuracy\": {\"score\": 0, \"rationale\": \"Evaluation failed\"},\n",
    "                \"overall\": {\"score\": 0, \"rationale\": \"Evaluation failed\"},\n",
    "                \"average_score\": 0\n",
    "            }\n",
    "\n",
    "# Initialize our custom evaluators\n",
    "expected_pattern_eval = ExpectedPatternEvaluator()\n",
    "conference_assistant_eval = ConferenceAssistantEvaluator(model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb45562",
   "metadata": {},
   "source": [
    "## Run Evaluation on the Test Dataset\n",
    "\n",
    "Now let's evaluate our PyCon assistant using both built-in and custom evaluators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "340429db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-29 13:27:04 -0700][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2025-04-29 13:27:04 -0700][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2025-04-29 13:27:04 -0700][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2025-04-29 13:27:04 -0700][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2025-04-29 13:27:04 -0700][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2025-04-29 13:27:04 -0700][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2025-04-29 13:27:04 -0700][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_groundedness_20250429_132704_038433, log path: /home/llawrence/.promptflow/.runs/azure_ai_evaluation_evaluators_groundedness_20250429_132704_038433/logs.txt\n",
      "[2025-04-29 13:27:04 -0700][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2025-04-29 13:27:04 -0700][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_groundedness_20250429_132704_038433, log path: /home/llawrence/.promptflow/.runs/azure_ai_evaluation_evaluators_groundedness_20250429_132704_038433/logs.txt\n",
      "[2025-04-29 13:27:04 -0700][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2025-04-29 13:27:04 -0700][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2025-04-29 13:27:04 -0700][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_conference_assistant_20250429_132704_046209, log path: /home/llawrence/.promptflow/.runs/azure_ai_evaluation_evaluators_conference_assistant_20250429_132704_046209/logs.txt\n",
      "[2025-04-29 13:27:04 -0700][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_relevance_20250429_132704_039703, log path: /home/llawrence/.promptflow/.runs/azure_ai_evaluation_evaluators_relevance_20250429_132704_039703/logs.txt\n",
      "[2025-04-29 13:27:04 -0700][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_conference_assistant_20250429_132704_046209, log path: /home/llawrence/.promptflow/.runs/azure_ai_evaluation_evaluators_conference_assistant_20250429_132704_046209/logs.txt\n",
      "[2025-04-29 13:27:04 -0700][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_relevance_20250429_132704_039703, log path: /home/llawrence/.promptflow/.runs/azure_ai_evaluation_evaluators_relevance_20250429_132704_039703/logs.txt\n",
      "[2025-04-29 13:27:04 -0700][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_expected_pattern_20250429_132704_045046, log path: /home/llawrence/.promptflow/.runs/azure_ai_evaluation_evaluators_expected_pattern_20250429_132704_045046/logs.txt\n",
      "[2025-04-29 13:27:04 -0700][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_fluency_20250429_132704_042531, log path: /home/llawrence/.promptflow/.runs/azure_ai_evaluation_evaluators_fluency_20250429_132704_042531/logs.txt\n",
      "[2025-04-29 13:27:04 -0700][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_expected_pattern_20250429_132704_045046, log path: /home/llawrence/.promptflow/.runs/azure_ai_evaluation_evaluators_expected_pattern_20250429_132704_045046/logs.txt\n",
      "[2025-04-29 13:27:04 -0700][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_fluency_20250429_132704_042531, log path: /home/llawrence/.promptflow/.runs/azure_ai_evaluation_evaluators_fluency_20250429_132704_042531/logs.txt\n",
      "[2025-04-29 13:27:04 -0700][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2025-04-29 13:27:04 -0700][promptflow._core.entry_meta_generator][WARNING] - Generate meta in current process and timeout won't take effect. Please handle timeout manually outside current process.\n",
      "[2025-04-29 13:27:04 -0700][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_coherence_20250429_132704_041167, log path: /home/llawrence/.promptflow/.runs/azure_ai_evaluation_evaluators_coherence_20250429_132704_041167/logs.txt\n",
      "[2025-04-29 13:27:04 -0700][promptflow._sdk._orchestrator.run_submitter][INFO] - Submitting run azure_ai_evaluation_evaluators_coherence_20250429_132704_041167, log path: /home/llawrence/.promptflow/.runs/azure_ai_evaluation_evaluators_coherence_20250429_132704_041167/logs.txt\n",
      "[2025-04-29 13:27:05 -0700][promptflow._sdk._orchestrator.run_submitter][WARNING] - 10 out of 10 runs failed in batch run.\n",
      " Please check out /home/llawrence/.promptflow/.runs/azure_ai_evaluation_evaluators_coherence_20250429_132704_041167 for more details.\n",
      "[2025-04-29 13:27:05 -0700][promptflow._sdk._orchestrator.run_submitter][WARNING] - 10 out of 10 runs failed in batch run.\n",
      " Please check out /home/llawrence/.promptflow/.runs/azure_ai_evaluation_evaluators_coherence_20250429_132704_041167 for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-29 13:27:04 -0700  432215 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n",
      "2025-04-29 13:27:04 -0700  432215 execution.bulk     INFO     Finished 10 / 10 lines.\n",
      "2025-04-29 13:27:04 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.02 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "2025-04-29 13:27:04 -0700  432215 execution          ERROR    10/10 flow run failed, indexes: [3,6,0,1,9,4,7,2,5,8], exception of index 3: (UserError) CoherenceEvaluator: Either 'conversation' or individual inputs must be provided.\n",
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"azure_ai_evaluation_evaluators_coherence_20250429_132704_041167\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2025-04-29 13:27:04.078031-07:00\"\n",
      "Duration: \"0:00:01.645036\"\n",
      "Output path: \"/home/llawrence/.promptflow/.runs/azure_ai_evaluation_evaluators_coherence_20250429_132704_041167\"\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'ExpectedPatternEvaluator' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/usr/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'ConferenceAssistantEvaluator' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 1 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 2.71 seconds. Estimated time for incomplete lines: 24.39 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 2.71 seconds. Estimated time for incomplete lines: 24.39 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 1 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 2.75 seconds. Estimated time for incomplete lines: 24.75 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 2 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 1.38 seconds. Estimated time for incomplete lines: 11.04 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 1 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 2.75 seconds. Estimated time for incomplete lines: 24.75 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 2 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 1.38 seconds. Estimated time for incomplete lines: 11.04 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 2 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 1.51 seconds. Estimated time for incomplete lines: 12.08 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 2 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 1.51 seconds. Estimated time for incomplete lines: 12.08 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 3 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 1.01 seconds. Estimated time for incomplete lines: 7.07 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 1 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 3.03 seconds. Estimated time for incomplete lines: 27.27 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 3 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 1.02 seconds. Estimated time for incomplete lines: 7.14 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 2 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 1.52 seconds. Estimated time for incomplete lines: 12.16 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 3 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 1.01 seconds. Estimated time for incomplete lines: 7.07 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 1 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 3.03 seconds. Estimated time for incomplete lines: 27.27 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 3 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 1.02 seconds. Estimated time for incomplete lines: 7.14 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 2 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 1.52 seconds. Estimated time for incomplete lines: 12.16 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 4 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 4 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.78 seconds. Estimated time for incomplete lines: 4.68 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 4 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.78 seconds. Estimated time for incomplete lines: 4.68 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 4 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.79 seconds. Estimated time for incomplete lines: 4.74 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 3 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 5 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 1.05 seconds. Estimated time for incomplete lines: 7.35 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.63 seconds. Estimated time for incomplete lines: 3.15 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.79 seconds. Estimated time for incomplete lines: 4.74 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 3 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 5 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 1.05 seconds. Estimated time for incomplete lines: 7.35 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.63 seconds. Estimated time for incomplete lines: 3.15 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 4 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.79 seconds. Estimated time for incomplete lines: 4.74 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 4 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.79 seconds. Estimated time for incomplete lines: 4.74 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 6 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 5 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.54 seconds. Estimated time for incomplete lines: 2.16 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 5 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.64 seconds. Estimated time for incomplete lines: 3.2 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.65 seconds. Estimated time for incomplete lines: 3.25 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 6 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 5 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.54 seconds. Estimated time for incomplete lines: 2.16 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 5 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.64 seconds. Estimated time for incomplete lines: 3.2 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.65 seconds. Estimated time for incomplete lines: 3.25 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 7 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.47 seconds. Estimated time for incomplete lines: 1.41 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 8 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.41 seconds. Estimated time for incomplete lines: 0.82 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 7 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.47 seconds. Estimated time for incomplete lines: 1.41 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 8 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.41 seconds. Estimated time for incomplete lines: 0.82 seconds.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Finished 6 / 10 lines.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.54 seconds. Estimated time for incomplete lines: 2.16 seconds.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Finished 6 / 10 lines.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.54 seconds. Estimated time for incomplete lines: 2.16 seconds.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     ERROR    The spawned fork process manager failed to start.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     ERROR    The spawned fork process manager failed to start.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     ERROR    The spawned fork process manager failed to start.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     ERROR    The spawned fork process manager failed to start.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Finished 7 / 10 lines.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.48 seconds. Estimated time for incomplete lines: 1.44 seconds.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Finished 7 / 10 lines.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.48 seconds. Estimated time for incomplete lines: 1.44 seconds.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     ERROR    The spawned fork process manager failed to start.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     ERROR    The spawned fork process manager failed to start.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     ERROR    The spawned fork process manager failed to start.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     ERROR    The spawned fork process manager failed to start.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     ERROR    The spawned fork process manager failed to start.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     ERROR    The spawned fork process manager failed to start.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     ERROR    The spawned fork process manager failed to start.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     ERROR    The spawned fork process manager failed to start.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     ERROR    The spawned fork process manager failed to start.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     ERROR    The spawned fork process manager failed to start.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     ERROR    The spawned fork process manager failed to start.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     ERROR    The spawned fork process manager failed to start.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Finished 9 / 10 lines.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.39 seconds. Estimated time for incomplete lines: 0.39 seconds.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Finished 9 / 10 lines.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.39 seconds. Estimated time for incomplete lines: 0.39 seconds.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Finished 6 / 10 lines.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.6 seconds. Estimated time for incomplete lines: 2.4 seconds.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Finished 6 / 10 lines.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.6 seconds. Estimated time for incomplete lines: 2.4 seconds.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Finished 7 / 10 lines.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.54 seconds. Estimated time for incomplete lines: 1.62 seconds.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Finished 7 / 10 lines.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.54 seconds. Estimated time for incomplete lines: 1.62 seconds.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Finished 8 / 10 lines.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.47 seconds. Estimated time for incomplete lines: 0.94 seconds.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Finished 8 / 10 lines.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.47 seconds. Estimated time for incomplete lines: 0.94 seconds.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Finished 8 / 10 lines.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.48 seconds. Estimated time for incomplete lines: 0.96 seconds.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Finished 8 / 10 lines.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.48 seconds. Estimated time for incomplete lines: 0.96 seconds.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Finished 9 / 10 lines.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.45 seconds. Estimated time for incomplete lines: 0.45 seconds.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Finished 9 / 10 lines.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.45 seconds. Estimated time for incomplete lines: 0.45 seconds.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     ERROR    Error occurred while executing batch run. Exception: Failed to start spawned fork process manager\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     ERROR    Error occurred while executing batch run. Exception: Failed to start spawned fork process manager\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-29 13:27:08 -0700][promptflow._sdk._orchestrator.run_submitter][WARNING] - Run azure_ai_evaluation_evaluators_expected_pattern_20250429_132704_045046 failed when executing in executor with exception Failed to start spawned fork process manager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-29 13:27:09 -0700  432215 execution.bulk     ERROR    Error occurred while executing batch run. Exception: Failed to start spawned fork process manager\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-04-29 13:27:09 -0700][promptflow._sdk._orchestrator.run_submitter][WARNING] - Run azure_ai_evaluation_evaluators_conference_assistant_20250429_132704_046209 failed when executing in executor with exception Failed to start spawned fork process manager.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-29 13:27:10 -0700  432215 execution.bulk     INFO     Finished 10 / 10 lines.\n",
      "2025-04-29 13:27:10 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.55 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "2025-04-29 13:27:10 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.55 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "2025-04-29 13:27:04 -0700  432215 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 1 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 2.71 seconds. Estimated time for incomplete lines: 24.39 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 2 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 1.51 seconds. Estimated time for incomplete lines: 12.08 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 3 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 1.01 seconds. Estimated time for incomplete lines: 7.07 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 4 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.79 seconds. Estimated time for incomplete lines: 4.74 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 5 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.65 seconds. Estimated time for incomplete lines: 3.25 seconds.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Finished 6 / 10 lines.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.6 seconds. Estimated time for incomplete lines: 2.4 seconds.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Finished 7 / 10 lines.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.54 seconds. Estimated time for incomplete lines: 1.62 seconds.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Finished 8 / 10 lines.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.48 seconds. Estimated time for incomplete lines: 0.96 seconds.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Finished 9 / 10 lines.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.45 seconds. Estimated time for incomplete lines: 0.45 seconds.\n",
      "2025-04-29 13:27:10 -0700  432215 execution.bulk     INFO     Finished 10 / 10 lines.\n",
      "2025-04-29 13:27:10 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.55 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"azure_ai_evaluation_evaluators_groundedness_20250429_132704_038433\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2025-04-29 13:27:04.069617-07:00\"\n",
      "Duration: \"0:00:06.651155\"\n",
      "Output path: \"/home/llawrence/.promptflow/.runs/azure_ai_evaluation_evaluators_groundedness_20250429_132704_038433\"\n",
      "\n",
      "2025-04-29 13:27:04 -0700  432215 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 1 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 2.71 seconds. Estimated time for incomplete lines: 24.39 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 2 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 1.51 seconds. Estimated time for incomplete lines: 12.08 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 3 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 1.01 seconds. Estimated time for incomplete lines: 7.07 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 4 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.79 seconds. Estimated time for incomplete lines: 4.74 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 5 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.65 seconds. Estimated time for incomplete lines: 3.25 seconds.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Finished 6 / 10 lines.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.6 seconds. Estimated time for incomplete lines: 2.4 seconds.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Finished 7 / 10 lines.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.54 seconds. Estimated time for incomplete lines: 1.62 seconds.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Finished 8 / 10 lines.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.48 seconds. Estimated time for incomplete lines: 0.96 seconds.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Finished 9 / 10 lines.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.45 seconds. Estimated time for incomplete lines: 0.45 seconds.\n",
      "2025-04-29 13:27:10 -0700  432215 execution.bulk     INFO     Finished 10 / 10 lines.\n",
      "2025-04-29 13:27:10 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.55 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"azure_ai_evaluation_evaluators_groundedness_20250429_132704_038433\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2025-04-29 13:27:04.069617-07:00\"\n",
      "Duration: \"0:00:06.651155\"\n",
      "Output path: \"/home/llawrence/.promptflow/.runs/azure_ai_evaluation_evaluators_groundedness_20250429_132704_038433\"\n",
      "\n",
      "2025-04-29 13:27:12 -0700  432215 execution.bulk     INFO     Finished 9 / 10 lines.\n",
      "2025-04-29 13:27:12 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.84 seconds. Estimated time for incomplete lines: 0.84 seconds.\n",
      "2025-04-29 13:27:12 -0700  432215 execution.bulk     INFO     Finished 9 / 10 lines.\n",
      "2025-04-29 13:27:12 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.84 seconds. Estimated time for incomplete lines: 0.84 seconds.\n",
      "2025-04-29 13:27:12 -0700  432215 execution.bulk     INFO     Finished 10 / 10 lines.\n",
      "2025-04-29 13:27:12 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.8 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "2025-04-29 13:27:12 -0700  432215 execution.bulk     INFO     Finished 10 / 10 lines.\n",
      "2025-04-29 13:27:12 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.8 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "2025-04-29 13:27:04 -0700  432215 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 1 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 3.03 seconds. Estimated time for incomplete lines: 27.27 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 2 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 1.52 seconds. Estimated time for incomplete lines: 12.16 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 3 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 1.05 seconds. Estimated time for incomplete lines: 7.35 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 4 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.79 seconds. Estimated time for incomplete lines: 4.74 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 5 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.64 seconds. Estimated time for incomplete lines: 3.2 seconds.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Finished 6 / 10 lines.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.54 seconds. Estimated time for incomplete lines: 2.16 seconds.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Finished 7 / 10 lines.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.48 seconds. Estimated time for incomplete lines: 1.44 seconds.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Finished 8 / 10 lines.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.47 seconds. Estimated time for incomplete lines: 0.94 seconds.\n",
      "2025-04-29 13:27:12 -0700  432215 execution.bulk     INFO     Finished 9 / 10 lines.\n",
      "2025-04-29 13:27:12 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.84 seconds. Estimated time for incomplete lines: 0.84 seconds.\n",
      "2025-04-29 13:27:12 -0700  432215 execution.bulk     INFO     Finished 10 / 10 lines.\n",
      "2025-04-29 13:27:12 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.8 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"azure_ai_evaluation_evaluators_fluency_20250429_132704_042531\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2025-04-29 13:27:04.069834-07:00\"\n",
      "Duration: \"0:00:08.725934\"\n",
      "Output path: \"/home/llawrence/.promptflow/.runs/azure_ai_evaluation_evaluators_fluency_20250429_132704_042531\"\n",
      "\n",
      "2025-04-29 13:27:04 -0700  432215 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 1 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 3.03 seconds. Estimated time for incomplete lines: 27.27 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 2 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 1.52 seconds. Estimated time for incomplete lines: 12.16 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 3 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 1.05 seconds. Estimated time for incomplete lines: 7.35 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 4 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.79 seconds. Estimated time for incomplete lines: 4.74 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 5 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.64 seconds. Estimated time for incomplete lines: 3.2 seconds.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Finished 6 / 10 lines.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.54 seconds. Estimated time for incomplete lines: 2.16 seconds.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Finished 7 / 10 lines.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.48 seconds. Estimated time for incomplete lines: 1.44 seconds.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Finished 8 / 10 lines.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.47 seconds. Estimated time for incomplete lines: 0.94 seconds.\n",
      "2025-04-29 13:27:12 -0700  432215 execution.bulk     INFO     Finished 9 / 10 lines.\n",
      "2025-04-29 13:27:12 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.84 seconds. Estimated time for incomplete lines: 0.84 seconds.\n",
      "2025-04-29 13:27:12 -0700  432215 execution.bulk     INFO     Finished 10 / 10 lines.\n",
      "2025-04-29 13:27:12 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.8 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"azure_ai_evaluation_evaluators_fluency_20250429_132704_042531\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2025-04-29 13:27:04.069834-07:00\"\n",
      "Duration: \"0:00:08.725934\"\n",
      "Output path: \"/home/llawrence/.promptflow/.runs/azure_ai_evaluation_evaluators_fluency_20250429_132704_042531\"\n",
      "\n",
      "2025-04-29 13:27:13 -0700  432215 execution.bulk     INFO     Finished 10 / 10 lines.\n",
      "2025-04-29 13:27:13 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.85 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "2025-04-29 13:27:13 -0700  432215 execution.bulk     INFO     Finished 10 / 10 lines.\n",
      "2025-04-29 13:27:13 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.85 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "2025-04-29 13:27:04 -0700  432215 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 1 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 2.75 seconds. Estimated time for incomplete lines: 24.75 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 2 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 1.38 seconds. Estimated time for incomplete lines: 11.04 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 3 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 1.02 seconds. Estimated time for incomplete lines: 7.14 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 4 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.78 seconds. Estimated time for incomplete lines: 4.68 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 5 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.63 seconds. Estimated time for incomplete lines: 3.15 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 6 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.54 seconds. Estimated time for incomplete lines: 2.16 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 7 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.47 seconds. Estimated time for incomplete lines: 1.41 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 8 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.41 seconds. Estimated time for incomplete lines: 0.82 seconds.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Finished 9 / 10 lines.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.39 seconds. Estimated time for incomplete lines: 0.39 seconds.\n",
      "2025-04-29 13:27:13 -0700  432215 execution.bulk     INFO     Finished 10 / 10 lines.\n",
      "2025-04-29 13:27:13 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.85 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"azure_ai_evaluation_evaluators_relevance_20250429_132704_039703\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2025-04-29 13:27:04.071995-07:00\"\n",
      "Duration: \"0:00:09.678607\"\n",
      "Output path: \"/home/llawrence/.promptflow/.runs/azure_ai_evaluation_evaluators_relevance_20250429_132704_039703\"\n",
      "\n",
      "2025-04-29 13:27:04 -0700  432215 execution.bulk     INFO     Current thread is not main thread, skip signal handler registration in BatchEngine.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 1 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 2.75 seconds. Estimated time for incomplete lines: 24.75 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 2 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 1.38 seconds. Estimated time for incomplete lines: 11.04 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 3 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 1.02 seconds. Estimated time for incomplete lines: 7.14 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 4 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.78 seconds. Estimated time for incomplete lines: 4.68 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 5 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.63 seconds. Estimated time for incomplete lines: 3.15 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 6 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.54 seconds. Estimated time for incomplete lines: 2.16 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 7 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.47 seconds. Estimated time for incomplete lines: 1.41 seconds.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Finished 8 / 10 lines.\n",
      "2025-04-29 13:27:07 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.41 seconds. Estimated time for incomplete lines: 0.82 seconds.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Finished 9 / 10 lines.\n",
      "2025-04-29 13:27:08 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.39 seconds. Estimated time for incomplete lines: 0.39 seconds.\n",
      "2025-04-29 13:27:13 -0700  432215 execution.bulk     INFO     Finished 10 / 10 lines.\n",
      "2025-04-29 13:27:13 -0700  432215 execution.bulk     INFO     Average execution time for completed lines: 0.85 seconds. Estimated time for incomplete lines: 0.0 seconds.\n",
      "======= Run Summary =======\n",
      "\n",
      "Run name: \"azure_ai_evaluation_evaluators_relevance_20250429_132704_039703\"\n",
      "Run status: \"Completed\"\n",
      "Start time: \"2025-04-29 13:27:04.071995-07:00\"\n",
      "Duration: \"0:00:09.678607\"\n",
      "Output path: \"/home/llawrence/.promptflow/.runs/azure_ai_evaluation_evaluators_relevance_20250429_132704_039703\"\n",
      "\n"
     ]
    },
    {
     "ename": "EvaluationException",
     "evalue": "(InternalError) Failed to start spawned fork process manager",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mSpawnedForkProcessManagerStartFailure\u001b[39m     Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/pycon/.venv/lib/python3.11/site-packages/azure/ai/evaluation/_evaluate/_evaluate.py:678\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(data, evaluators, evaluation_name, target, evaluator_config, azure_ai_project, output_path, fail_on_evaluator_errors, **kwargs)\u001b[39m\n\u001b[32m    677\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m678\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m        \u001b[49m\u001b[43mevaluation_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevaluation_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    680\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    682\u001b[39m \u001b[43m        \u001b[49m\u001b[43mevaluators\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevaluators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    683\u001b[39m \u001b[43m        \u001b[49m\u001b[43mevaluator_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevaluator_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    684\u001b[39m \u001b[43m        \u001b[49m\u001b[43mazure_ai_project\u001b[49m\u001b[43m=\u001b[49m\u001b[43mazure_ai_project\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfail_on_evaluator_errors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfail_on_evaluator_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    690\u001b[39m     \u001b[38;5;66;03m# Handle multiprocess bootstrap error\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/pycon/.venv/lib/python3.11/site-packages/azure/ai/evaluation/_evaluate/_evaluate.py:847\u001b[39m, in \u001b[36m_evaluate\u001b[39m\u001b[34m(evaluators, evaluation_name, target, data, evaluator_config, azure_ai_project, output_path, fail_on_evaluator_errors, **kwargs)\u001b[39m\n\u001b[32m    846\u001b[39m     \u001b[38;5;66;03m# get_details needs to be called within EvalRunContext scope in order to have user agent populated\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m847\u001b[39m     per_evaluator_results: Dict[\u001b[38;5;28mstr\u001b[39m, __EvaluatorInfo] = \u001b[43m{\u001b[49m\n\u001b[32m    848\u001b[39m \u001b[43m        \u001b[49m\u001b[43mevaluator_name\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    849\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresult\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_run_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_details\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_results\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    850\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetrics\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_run_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    851\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_summary\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_run_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_run_summary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    852\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m    853\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevaluator_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mruns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    854\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m    856\u001b[39m \u001b[38;5;66;03m# Concatenate all results\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/pycon/.venv/lib/python3.11/site-packages/azure/ai/evaluation/_evaluate/_evaluate.py:849\u001b[39m, in \u001b[36m<dictcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    846\u001b[39m     \u001b[38;5;66;03m# get_details needs to be called within EvalRunContext scope in order to have user agent populated\u001b[39;00m\n\u001b[32m    847\u001b[39m     per_evaluator_results: Dict[\u001b[38;5;28mstr\u001b[39m, __EvaluatorInfo] = {\n\u001b[32m    848\u001b[39m         evaluator_name: {\n\u001b[32m--> \u001b[39m\u001b[32m849\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mresult\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mbatch_run_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_details\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_results\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m,\n\u001b[32m    850\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmetrics\u001b[39m\u001b[33m\"\u001b[39m: batch_run_client.get_metrics(run),\n\u001b[32m    851\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mrun_summary\u001b[39m\u001b[33m\"\u001b[39m: batch_run_client.get_run_summary(run),\n\u001b[32m    852\u001b[39m         }\n\u001b[32m    853\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m evaluator_name, run \u001b[38;5;129;01min\u001b[39;00m runs.items()\n\u001b[32m    854\u001b[39m     }\n\u001b[32m    856\u001b[39m \u001b[38;5;66;03m# Concatenate all results\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/pycon/.venv/lib/python3.11/site-packages/azure/ai/evaluation/_evaluate/_batch_run/proxy_client.py:74\u001b[39m, in \u001b[36mProxyClient.get_details\u001b[39m\u001b[34m(self, client_run, all_results)\u001b[39m\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_details\u001b[39m(\u001b[38;5;28mself\u001b[39m, client_run: BatchClientRun, all_results: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m) -> pd.DataFrame:\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m     run: Run = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient_run\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     result_df = \u001b[38;5;28mself\u001b[39m._pf_client.get_details(run, all_results=all_results)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/pycon/.venv/lib/python3.11/site-packages/azure/ai/evaluation/_evaluate/_batch_run/proxy_client.py:109\u001b[39m, in \u001b[36mProxyClient.get_result\u001b[39m\u001b[34m(run)\u001b[39m\n\u001b[32m    107\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_result\u001b[39m(run: BatchClientRun) -> Run:\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mProxyRun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/concurrent/futures/_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m     \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/concurrent/futures/thread.py:58\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/pycon/.venv/lib/python3.11/site-packages/promptflow/_sdk/_pf_client.py:301\u001b[39m, in \u001b[36mPFClient.run\u001b[39m\u001b[34m(self, flow, data, run, column_mapping, variant, connections, environment_variables, name, display_name, tags, resume_from, code, init, **kwargs)\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Run flow against provided data or run.\u001b[39;00m\n\u001b[32m    247\u001b[39m \n\u001b[32m    248\u001b[39m \u001b[33;03m.. note::\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    299\u001b[39m \u001b[33;03m:rtype: ~promptflow.entities.Run\u001b[39;00m\n\u001b[32m    300\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m301\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    302\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflow\u001b[49m\u001b[43m=\u001b[49m\u001b[43mflow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    303\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    304\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrun\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    305\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumn_mapping\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumn_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    306\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvariant\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvariant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    307\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconnections\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconnections\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[43m    \u001b[49m\u001b[43menvironment_variables\u001b[49m\u001b[43m=\u001b[49m\u001b[43menvironment_variables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdisplay_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisplay_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresume_from\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m    \u001b[49m\u001b[43minit\u001b[49m\u001b[43m=\u001b[49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/pycon/.venv/lib/python3.11/site-packages/promptflow/_sdk/_pf_client.py:226\u001b[39m, in \u001b[36mPFClient._run\u001b[39m\u001b[34m(self, flow, data, run, column_mapping, variant, connections, environment_variables, properties, name, display_name, tags, resume_from, code, init, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m run = Run(\n\u001b[32m    211\u001b[39m     name=name,\n\u001b[32m    212\u001b[39m     display_name=display_name,\n\u001b[32m   (...)\u001b[39m\u001b[32m    224\u001b[39m     dynamic_callable=dynamic_callable,\n\u001b[32m    225\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m226\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mruns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_or_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/pycon/.venv/lib/python3.11/site-packages/promptflow/_sdk/_telemetry/activity.py:265\u001b[39m, in \u001b[36mmonitor_operation.<locals>.monitor.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    264\u001b[39m     thread.start()\n\u001b[32m--> \u001b[39m\u001b[32m265\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/pycon/.venv/lib/python3.11/site-packages/promptflow/_sdk/operations/_run_operations.py:135\u001b[39m, in \u001b[36mRunOperations.create_or_update\u001b[39m\u001b[34m(self, run, **kwargs)\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpromptflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_sdk\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_orchestrator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RunSubmitter\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m created_run = \u001b[43mRunSubmitter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/pycon/.venv/lib/python3.11/site-packages/promptflow/_sdk/_orchestrator/run_submitter.py:52\u001b[39m, in \u001b[36mRunSubmitter.submit\u001b[39m\u001b[34m(self, run, stream, **kwargs)\u001b[39m\n\u001b[32m     51\u001b[39m     wait(tasks, return_when=ALL_COMPLETED)\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     task_results = \u001b[43m[\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# upload run to cloud if the trace destination is set to cloud\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/pycon/.venv/lib/python3.11/site-packages/promptflow/_sdk/_orchestrator/run_submitter.py:52\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     51\u001b[39m     wait(tasks, return_when=ALL_COMPLETED)\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     task_results = [\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m tasks]\n\u001b[32m     54\u001b[39m \u001b[38;5;66;03m# upload run to cloud if the trace destination is set to cloud\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/concurrent/futures/_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m     \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/concurrent/futures/thread.py:58\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/pycon/.venv/lib/python3.11/site-packages/promptflow/_sdk/_orchestrator/run_submitter.py:134\u001b[39m, in \u001b[36mRunSubmitter._run_bulk\u001b[39m\u001b[34m(self, run, stream, **kwargs)\u001b[39m\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m flow_overwrite_context(\n\u001b[32m    132\u001b[39m     flow_obj, tuning_node, variant, connections=run.connections, init_kwargs=run.init\n\u001b[32m    133\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m flow:\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_submit_bulk_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflow\u001b[49m\u001b[43m=\u001b[49m\u001b[43mflow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_storage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_storage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/pycon/.venv/lib/python3.11/site-packages/promptflow/_sdk/_orchestrator/run_submitter.py:222\u001b[39m, in \u001b[36mRunSubmitter._submit_bulk_run\u001b[39m\u001b[34m(self, flow, run, local_storage, **kwargs)\u001b[39m\n\u001b[32m    220\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, UserErrorException):\n\u001b[32m    221\u001b[39m         \u001b[38;5;66;03m# for other errors, raise it to user to help debug root cause.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# won't raise the exception since it's already included in run object.\u001b[39;00m\n\u001b[32m    224\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    225\u001b[39m     \u001b[38;5;66;03m# persist snapshot and result\u001b[39;00m\n\u001b[32m    226\u001b[39m     \u001b[38;5;66;03m# snapshot: flow directory\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/pycon/.venv/lib/python3.11/site-packages/promptflow/_sdk/_orchestrator/run_submitter.py:188\u001b[39m, in \u001b[36mRunSubmitter._submit_bulk_run\u001b[39m\u001b[34m(self, flow, run, local_storage, **kwargs)\u001b[39m\n\u001b[32m    178\u001b[39m batch_engine = BatchEngine(\n\u001b[32m    179\u001b[39m     run._dynamic_callable \u001b[38;5;129;01mor\u001b[39;00m flow.path,\n\u001b[32m    180\u001b[39m     flow.code,\n\u001b[32m   (...)\u001b[39m\u001b[32m    186\u001b[39m     **kwargs,\n\u001b[32m    187\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m188\u001b[39m batch_result = \u001b[43mbatch_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_dirs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_dirs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_mapping\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumn_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_storage\u001b[49m\u001b[43m.\u001b[49m\u001b[43moutputs_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresume_from_run_storage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_run_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresume_from_run_output_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_run_storage\u001b[49m\u001b[43m.\u001b[49m\u001b[43moutputs_folder\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresume_from_run_storage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    196\u001b[39m error_logs = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/pycon/.venv/lib/python3.11/site-packages/promptflow/batch/_batch_engine.py:271\u001b[39m, in \u001b[36mBatchEngine.run\u001b[39m\u001b[34m(self, input_dirs, inputs_mapping, output_dir, run_id, max_lines_count, raise_on_line_failure, resume_from_run_storage, resume_from_run_output_dir, executor_proxy)\u001b[39m\n\u001b[32m    270\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, PromptflowException):\n\u001b[32m--> \u001b[39m\u001b[32m271\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    272\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    273\u001b[39m     \u001b[38;5;66;03m# for unexpected error, we need to wrap it to SystemErrorException to allow us to see the stack trace.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/pycon/.venv/lib/python3.11/site-packages/promptflow/batch/_batch_engine.py:258\u001b[39m, in \u001b[36mBatchEngine.run\u001b[39m\u001b[34m(self, input_dirs, inputs_mapping, output_dir, run_id, max_lines_count, raise_on_line_failure, resume_from_run_storage, resume_from_run_output_dir, executor_proxy)\u001b[39m\n\u001b[32m    257\u001b[39m     \u001b[38;5;66;03m# run flow in batch mode\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43masync_run_allowing_running_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_exec_in_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mraise_on_line_failure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprevious_run_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/pycon/.venv/lib/python3.11/site-packages/promptflow/_utils/async_utils.py:96\u001b[39m, in \u001b[36masync_run_allowing_running_loop\u001b[39m\u001b[34m(async_func, *args, **kwargs)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_invoke_async_with_sigint_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43masync_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/asyncio/runners.py:190\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(main, debug)\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug=debug) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/asyncio/runners.py:118\u001b[39m, in \u001b[36mRunner.run\u001b[39m\u001b[34m(self, coro, context)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.CancelledError:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/asyncio/base_events.py:654\u001b[39m, in \u001b[36mBaseEventLoop.run_until_complete\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m    652\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mEvent loop stopped before Future completed.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m654\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m future.result()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/pycon/.venv/lib/python3.11/site-packages/promptflow/_utils/async_utils.py:65\u001b[39m, in \u001b[36m_invoke_async_with_sigint_handler\u001b[39m\u001b[34m(async_func, *args, **kwargs)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _should_update_sigint():\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m async_func(*args, **kwargs)\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/pycon/.venv/lib/python3.11/site-packages/promptflow/batch/_batch_engine.py:418\u001b[39m, in \u001b[36mBatchEngine._exec_in_task\u001b[39m\u001b[34m(self, batch_inputs, run_id, output_dir, raise_on_line_failure, previous_line_results)\u001b[39m\n\u001b[32m    417\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m BatchResult.create(\u001b[38;5;28mself\u001b[39m._start_time, datetime.utcnow(), line_results, aggr_result, exception=ex)\n\u001b[32m--> \u001b[39m\u001b[32m418\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m task.result()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/pycon/.venv/lib/python3.11/site-packages/promptflow/batch/_batch_engine.py:477\u001b[39m, in \u001b[36mBatchEngine._exec\u001b[39m\u001b[34m(self, batch_inputs, run_id, output_dir, raise_on_line_failure, previous_line_results, line_results, aggr_result)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._batch_use_async \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m._executor_proxy, PythonExecutorProxy):\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     results, is_timeout = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._executor_proxy._exec_batch(\n\u001b[32m    478\u001b[39m         inputs_to_run,\n\u001b[32m    479\u001b[39m         output_dir,\n\u001b[32m    480\u001b[39m         run_id,\n\u001b[32m    481\u001b[39m         batch_timeout_sec=\u001b[38;5;28mself\u001b[39m._batch_timeout_sec,\n\u001b[32m    482\u001b[39m         line_timeout_sec=\u001b[38;5;28mself\u001b[39m._line_timeout_sec,\n\u001b[32m    483\u001b[39m         worker_count=\u001b[38;5;28mself\u001b[39m._worker_count,\n\u001b[32m    484\u001b[39m     )\n\u001b[32m    485\u001b[39m     line_results.extend(results)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/pycon/.venv/lib/python3.11/site-packages/promptflow/_proxy/_python_executor_proxy.py:131\u001b[39m, in \u001b[36mPythonExecutorProxy._exec_batch\u001b[39m\u001b[34m(self, batch_inputs, output_dir, run_id, batch_timeout_sec, line_timeout_sec, worker_count)\u001b[39m\n\u001b[32m    130\u001b[39m     line_number = [batch_input[\u001b[33m\"\u001b[39m\u001b[33mline_number\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m batch_input \u001b[38;5;129;01min\u001b[39;00m batch_inputs]\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m     line_results = \u001b[38;5;28;01mawait\u001b[39;00m pool.run(\u001b[38;5;28mzip\u001b[39m(line_number, batch_inputs))\n\u001b[32m    133\u001b[39m \u001b[38;5;66;03m# For bulk run, currently we need to add line results to run_tracker\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/pycon/.venv/lib/python3.11/site-packages/promptflow/executor/_line_execution_process_pool.py:299\u001b[39m, in \u001b[36mLineExecutionProcessPool.run\u001b[39m\u001b[34m(self, batch_inputs)\u001b[39m\n\u001b[32m    298\u001b[39m \u001b[38;5;66;03m# Check monitor status every 1 second\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m299\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_monitor_thread_pool_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio.sleep(\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/pycon/.venv/lib/python3.11/site-packages/promptflow/executor/_line_execution_process_pool.py:536\u001b[39m, in \u001b[36mLineExecutionProcessPool._monitor_thread_pool_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    532\u001b[39m         \u001b[38;5;66;03m# To ensure exceptions in thread-pool calls are propagated to the main process for proper handling\u001b[39;00m\n\u001b[32m    533\u001b[39m         \u001b[38;5;66;03m# The exceptions raised will be re-raised by the get() method.\u001b[39;00m\n\u001b[32m    534\u001b[39m         \u001b[38;5;66;03m# Related link:\u001b[39;00m\n\u001b[32m    535\u001b[39m         \u001b[38;5;66;03m# https://docs.python.org/3/library/multiprocessing.html#multiprocessing.pool.AsyncResult\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m536\u001b[39m         \u001b[43masync_task\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    537\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m PromptflowException:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/multiprocessing/pool.py:774\u001b[39m, in \u001b[36mApplyResult.get\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    773\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m774\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.11/multiprocessing/pool.py:125\u001b[39m, in \u001b[36mworker\u001b[39m\u001b[34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     result = (\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/pycon/.venv/lib/python3.11/site-packages/promptflow/executor/_line_execution_process_pool.py:336\u001b[39m, in \u001b[36mLineExecutionProcessPool._monitor_workers_and_process_tasks_in_thread\u001b[39m\u001b[34m(self, task_queue, result_dict, index, input_queue, output_queue)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_monitor_workers_and_process_tasks_in_thread\u001b[39m(\n\u001b[32m    328\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    329\u001b[39m     task_queue: Queue,\n\u001b[32m   (...)\u001b[39m\u001b[32m    334\u001b[39m ):\n\u001b[32m    335\u001b[39m     \u001b[38;5;66;03m# Get the process info of the thread monitoring from the manager.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m336\u001b[39m     index, process_id, process_name = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_processes_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_process_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    338\u001b[39m     \u001b[38;5;66;03m# The main loop of the thread, responsible for getting tasks from the task queue and\u001b[39;00m\n\u001b[32m    339\u001b[39m     \u001b[38;5;66;03m# processing them through the input queue, while also monitoring for terminate signals.\u001b[39;00m\n\u001b[32m    340\u001b[39m     \u001b[38;5;66;03m# Currently, it exits this loop only upon receiving a terminate signal or the batch run timeout.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/pycon/.venv/lib/python3.11/site-packages/promptflow/executor/_process_manager.py:133\u001b[39m, in \u001b[36mAbstractProcessManager.get_process_info\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mensure_healthy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/pycon/.venv/lib/python3.11/site-packages/promptflow/executor/_process_manager.py:347\u001b[39m, in \u001b[36mForkProcessManager.ensure_healthy\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    346\u001b[39m ex = SpawnedForkProcessManagerStartFailure()\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m ex\n",
      "\u001b[31mSpawnedForkProcessManagerStartFailure\u001b[39m: Failed to start spawned fork process manager",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mEvaluationException\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mazure\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mevaluation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m evaluate\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Run the evaluation on our test dataset\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m result = \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpycon_test_data.jsonl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# path to the data file\u001b[39;49;00m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluators\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgroundedness\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroundedness_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrelevance\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrelevance_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcoherence\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoherence_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfluency\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfluency_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mexpected_pattern\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpected_pattern_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mconference_assistant\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconference_assistant_eval\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Column mapping to tell the evaluator which columns to use\u001b[39;49;00m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluator_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgroundedness\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumn_mapping\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquery\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m$\u001b[39;49m\u001b[38;5;132;43;01m{data.query}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m$\u001b[39;49m\u001b[38;5;132;43;01m{data.context}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m$\u001b[39;49m\u001b[38;5;132;43;01m{data.response}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     21\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrelevance\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumn_mapping\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquery\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m$\u001b[39;49m\u001b[38;5;132;43;01m{data.query}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m$\u001b[39;49m\u001b[38;5;132;43;01m{data.response}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     27\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcoherence\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumn_mapping\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m$\u001b[39;49m\u001b[38;5;132;43;01m{data.response}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     32\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfluency\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumn_mapping\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m$\u001b[39;49m\u001b[38;5;132;43;01m{data.response}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     37\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mexpected_pattern\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumn_mapping\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m$\u001b[39;49m\u001b[38;5;132;43;01m{data.response}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mexpected_pattern\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m$\u001b[39;49m\u001b[38;5;132;43;01m{data.expected_pattern}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     43\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mconference_assistant\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumn_mapping\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquery\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m$\u001b[39;49m\u001b[38;5;132;43;01m{data.query}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m$\u001b[39;49m\u001b[38;5;132;43;01m{data.response}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcategory\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m$\u001b[39;49m\u001b[38;5;132;43;01m{data.category}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     50\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Output path to save results\u001b[39;49;00m\n\u001b[32m     54\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./pycon_assistant_evaluation_results.json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     55\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# Print evaluation results\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mAggregate Metrics:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/pycon/.venv/lib/python3.11/site-packages/azure/ai/evaluation/_evaluate/_evaluate.py:713\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(data, evaluators, evaluation_name, target, evaluator_config, azure_ai_project, output_path, fail_on_evaluator_errors, **kwargs)\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;66;03m# Ensure a consistent user experience when encountering errors by converting\u001b[39;00m\n\u001b[32m    711\u001b[39m \u001b[38;5;66;03m# all other exceptions to EvaluationException.\u001b[39;00m\n\u001b[32m    712\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, EvaluationException):\n\u001b[32m--> \u001b[39m\u001b[32m713\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m EvaluationException(\n\u001b[32m    714\u001b[39m         message=\u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    715\u001b[39m         target=ErrorTarget.EVALUATE,\n\u001b[32m    716\u001b[39m         category=ErrorCategory.FAILED_EXECUTION,\n\u001b[32m    717\u001b[39m         blame=ErrorBlame.SYSTEM_ERROR,\n\u001b[32m    718\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    720\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "\u001b[31mEvaluationException\u001b[39m: (InternalError) Failed to start spawned fork process manager"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import evaluate\n",
    "\n",
    "# Run the evaluation on our test dataset\n",
    "result = evaluate(\n",
    "    data=\"pycon_test_data.jsonl\",  # path to the data file\n",
    "    evaluators={\n",
    "        \"groundedness\": groundedness_eval,\n",
    "        \"relevance\": relevance_eval,\n",
    "        \"coherence\": coherence_eval,\n",
    "        \"fluency\": fluency_eval,\n",
    "        \"expected_pattern\": expected_pattern_eval,\n",
    "        \"conference_assistant\": conference_assistant_eval\n",
    "    },\n",
    "    # Column mapping to tell the evaluator which columns to use\n",
    "    evaluator_config={\n",
    "        \"groundedness\": {\n",
    "            \"column_mapping\": {\n",
    "                \"query\": \"${data.query}\",\n",
    "                \"context\": \"${data.context}\",\n",
    "                \"response\": \"${data.response}\"\n",
    "            }\n",
    "        },\n",
    "        \"relevance\": {\n",
    "            \"column_mapping\": {\n",
    "                \"query\": \"${data.query}\",\n",
    "                \"response\": \"${data.response}\"\n",
    "            }\n",
    "        },\n",
    "        \"coherence\": {\n",
    "            \"column_mapping\": {\n",
    "                \"response\": \"${data.response}\"\n",
    "            }\n",
    "        },\n",
    "        \"fluency\": {\n",
    "            \"column_mapping\": {\n",
    "                \"response\": \"${data.response}\"\n",
    "            }\n",
    "        },\n",
    "        \"expected_pattern\": {\n",
    "            \"column_mapping\": {\n",
    "                \"response\": \"${data.response}\",\n",
    "                \"expected_pattern\": \"${data.expected_pattern}\"\n",
    "            }\n",
    "        },\n",
    "        \"conference_assistant\": {\n",
    "            \"column_mapping\": {\n",
    "                \"query\": \"${data.query}\",\n",
    "                \"response\": \"${data.response}\",\n",
    "                \"category\": \"${data.category}\"\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    # Output path to save results\n",
    "    output_path=\"./pycon_assistant_evaluation_results.json\"\n",
    ")\n",
    "\n",
    "# Print evaluation results\n",
    "print(\"Aggregate Metrics:\")\n",
    "print(json.dumps(result[\"metrics\"], indent=2))\n",
    "print(\"\\nRow-level Results (first row):\")\n",
    "print(json.dumps(result[\"rows\"][0], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5200f4",
   "metadata": {},
   "source": [
    "## Analyze the Evaluation Results\n",
    "\n",
    "Let's analyze the evaluation results to identify strengths and areas for improvement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fa9320",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the evaluation results\n",
    "with open(\"pycon_assistant_evaluation_results.json\", \"r\") as f:\n",
    "    eval_results = json.load(f)\n",
    "\n",
    "# Create a DataFrame from the row-level results\n",
    "rows_data = []\n",
    "for row in eval_results[\"rows\"]:\n",
    "    row_data = {\n",
    "        \"query\": row[\"data\"][\"query\"],\n",
    "        \"category\": row[\"data\"][\"category\"],\n",
    "        \"groundedness\": row[\"outputs\"][\"groundedness\"][\"value\"] if \"groundedness\" in row[\"outputs\"] else None,\n",
    "        \"relevance\": row[\"outputs\"][\"relevance\"][\"value\"] if \"relevance\" in row[\"outputs\"] else None,\n",
    "        \"coherence\": row[\"outputs\"][\"coherence\"][\"value\"] if \"coherence\" in row[\"outputs\"] else None,\n",
    "        \"fluency\": row[\"outputs\"][\"fluency\"][\"value\"] if \"fluency\" in row[\"outputs\"] else None,\n",
    "        \"expected_pattern\": row[\"outputs\"][\"expected_pattern\"][\"value\"] if \"expected_pattern\" in row[\"outputs\"] else None,\n",
    "    }\n",
    "    \n",
    "    # Add conference assistant specific scores if available\n",
    "    if \"conference_assistant\" in row[\"outputs\"]:\n",
    "        conf_scores = row[\"outputs\"][\"conference_assistant\"]\n",
    "        if \"helpfulness\" in conf_scores:\n",
    "            row_data[\"helpfulness\"] = conf_scores[\"helpfulness\"][\"score\"]\n",
    "        if \"friendliness\" in conf_scores:\n",
    "            row_data[\"friendliness\"] = conf_scores[\"friendliness\"][\"score\"]\n",
    "        if \"conciseness\" in conf_scores:\n",
    "            row_data[\"conciseness\"] = conf_scores[\"conciseness\"][\"score\"]\n",
    "        if \"accuracy\" in conf_scores:\n",
    "            row_data[\"accuracy\"] = conf_scores[\"accuracy\"][\"score\"]\n",
    "        if \"overall\" in conf_scores:\n",
    "            row_data[\"overall\"] = conf_scores[\"overall\"][\"score\"]\n",
    "        if \"average_score\" in conf_scores:\n",
    "            row_data[\"average_score\"] = conf_scores[\"average_score\"]\n",
    "    \n",
    "    rows_data.append(row_data)\n",
    "\n",
    "df = pd.DataFrame(rows_data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"Evaluation Results by Query:\")\n",
    "display(df)\n",
    "\n",
    "# Create visualizations to analyze results\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Overall metrics by category\n",
    "category_scores = df.groupby('category').mean()\n",
    "category_scores.plot(kind='bar', figsize=(12, 6), title='Average Scores by Category')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylim(0, 5)  # Assuming scores are on a 0-5 scale\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create radar charts for each category\n",
    "categories = df['category'].unique()\n",
    "metrics = ['groundedness', 'relevance', 'coherence', 'fluency', 'helpfulness', 'friendliness', 'conciseness', 'accuracy']\n",
    "metrics = [m for m in metrics if m in df.columns]\n",
    "\n",
    "# Function to create a radar chart\n",
    "def create_radar_chart(category_data, title):\n",
    "    # Number of variables\n",
    "    N = len(metrics)\n",
    "    \n",
    "    # What will be the angle of each axis in the plot (divide the plot / number of variables)\n",
    "    angles = [n / float(N) * 2 * 3.14159 for n in range(N)]\n",
    "    angles += angles[:1]  # Close the loop\n",
    "    \n",
    "    # Get the values\n",
    "    values = category_data[metrics].mean().values.flatten().tolist()\n",
    "    values += values[:1]  # Close the loop\n",
    "    \n",
    "    # Create the plot\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax = plt.subplot(111, polar=True)\n",
    "    \n",
    "    # Draw one axis per variable and add labels\n",
    "    plt.xticks(angles[:-1], metrics, size=12)\n",
    "    \n",
    "    # Draw the chart\n",
    "    ax.plot(angles, values, linewidth=2, linestyle='solid')\n",
    "    ax.fill(angles, values, alpha=0.1)\n",
    "    \n",
    "    # Set y-axis limits\n",
    "    plt.ylim(0, 5)\n",
    "    \n",
    "    # Add title\n",
    "    plt.title(title, size=15)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create radar charts for overall and each category\n",
    "create_radar_chart(df, 'Overall Performance')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "for category in categories:\n",
    "    category_data = df[df['category'] == category]\n",
    "    create_radar_chart(category_data, f'Performance: {category} questions')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26584fd1",
   "metadata": {},
   "source": [
    "## Generate Insights and Recommendations\n",
    "\n",
    "Based on the evaluation results, let's generate insights and recommendations for improving the PyCon assistant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62ba167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate insights using Azure OpenAI\n",
    "def generate_insights(eval_results, metrics_df):\n",
    "    try:\n",
    "        # Format the data for analysis\n",
    "        metrics_str = metrics_df.to_string()\n",
    "        aggregate = json.dumps(eval_results[\"metrics\"], indent=2)\n",
    "        \n",
    "        insight_prompt = f\"\"\"\n",
    "        You are an expert in analyzing AI assistant evaluation results. Please analyze the following evaluation \n",
    "        results for a PyCon conference assistant and provide insights and recommendations.\n",
    "        \n",
    "        Evaluation Metrics by Query:\n",
    "        {metrics_str}\n",
    "        \n",
    "        Aggregate Metrics:\n",
    "        {aggregate}\n",
    "        \n",
    "        Please provide:\n",
    "        1. Key strengths (3-5 bullet points)\n",
    "        2. Areas for improvement (3-5 bullet points)\n",
    "        3. Specific recommendations to enhance the assistant's performance\n",
    "        4. Any patterns you notice across different question categories\n",
    "        \n",
    "        Format your response in Markdown with clear sections and bullet points.\n",
    "        \"\"\"\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=model_config[\"deployment_name\"],\n",
    "            messages=[{\"role\": \"user\", \"content\": insight_prompt}],\n",
    "            temperature=0.3,\n",
    "            max_tokens=1000\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating insights: {e}\")\n",
    "        return \"Error generating insights. Please check the evaluation results manually.\"\n",
    "\n",
    "# Generate and display insights\n",
    "insights = generate_insights(eval_results, df)\n",
    "print(insights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c935e2",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates how to evaluate a custom PyCon assistant copilot using the Azure AI Evaluation SDK. We've shown how to:\n",
    "\n",
    "1. Define a PyCon-specific system prompt to create a specialized assistant\n",
    "2. Create a test dataset with conference-specific questions\n",
    "3. Use built-in evaluators to assess basic quality metrics (groundedness, relevance, etc.)\n",
    "4. Create custom evaluators specifically designed for conference assistants\n",
    "5. Run comprehensive evaluations across different question categories\n",
    "6. Analyze results to identify strengths and areas for improvement\n",
    "7. Generate insights and recommendations for enhancing the assistant\n",
    "\n",
    "This evaluation framework can be extended to evaluate other types of specialized assistants by:\n",
    "- Modifying the system prompt for different domains\n",
    "- Creating domain-specific test datasets\n",
    "- Adding custom evaluators tailored to domain requirements\n",
    "- Adjusting analysis to focus on domain-specific performance metrics\n",
    "\n",
    "The Azure AI Evaluation SDK provides a powerful and flexible framework for evaluating and improving AI assistants across various specialized domains."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
